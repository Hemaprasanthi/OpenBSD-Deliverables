diff --git a/usr.sbin/vmctl/vmctl.c b/usr.sbin/vmctl/vmctl.c
index 195ffc8ab47..2505ff4b588 100644
--- a/usr.sbin/vmctl/vmctl.c
+++ b/usr.sbin/vmctl/vmctl.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmctl.c,v 1.71 2019/09/07 09:11:14 tobhe Exp $	*/
+/*	$OpenBSD: vmctl.c,v 1.74 2020/03/11 12:47:49 jasper Exp $	*/
 
 /*
  * Copyright (c) 2014 Mike Larkin <mlarkin@openbsd.org>
@@ -49,6 +49,137 @@ char info_name[VMM_MAX_NAME_LEN];
 enum actions info_action;
 unsigned int info_flags;
 
+int
+vm_balloon(uint32_t vm_id, const char *name, int memsize)
+{
+	struct vmop_balloon_params *vbp;
+	const char *s;
+
+	if ((vbp = calloc(1, sizeof(struct vmop_balloon_params))) == NULL)
+		return (ENOMEM);
+
+	if (name != NULL) {
+		/*
+		 * Allow VMs names with alphanumeric characters, dot, hyphen
+		 * and underscore. But disallow dot, hyphen and underscore at
+		 * the start.
+		 */
+		if (*name == '-' || *name == '.' || *name == '_')
+			errx(1, "invalid VM name");
+
+		for (s = name; *s != '\0'; ++s) {
+			if (!(isalnum(*s) || *s == '.' || *s == '-' ||
+			    *s == '_'))
+				errx(1, "invalid VM name");
+		}
+
+		if (strlcpy(vbp->vbp_name, name,
+		    sizeof(vbp->vbp_name)) >= sizeof(vbp->vbp_name))
+			errx(1, "vm name too long");
+	}
+
+	vbp->vbp_id = vm_id;
+	vbp->vbp_memsize = memsize;
+
+	imsg_compose(ibuf, IMSG_VMDOP_BALLOON_VM_REQUEST, 0, 0, -1,
+	    vbp, sizeof(struct vmop_balloon_params));
+
+	free(vbp);
+
+	return (0);
+}
+
+int
+vm_balloon_complete(struct imsg *imsg, int *ret)
+{
+	struct vmop_result *vmr;
+	int res;
+
+	if (imsg->hdr.type == IMSG_VMDOP_BALLOON_VM_RESPONSE) {
+		vmr = (struct vmop_result *)imsg->data;
+		res = vmr->vmr_result;
+		if (res) {
+			errno = res;
+			warn("balloon vm command failed");
+			*ret = EIO;
+		} else {
+			warnx("balloon adjusted on vm %d successfully",
+			    vmr->vmr_id);
+			*ret = 0;
+		}
+	} else {
+		warnx("unexpected response received from vmd");
+		*ret = EINVAL;
+	}
+
+	return (1);
+}
+
+int
+vm_stats(uint32_t vm_id, const char *name)
+{
+	struct vmop_stats_params *vsp;
+	const char *s;
+
+	if ((vsp = calloc(1, sizeof(struct vmop_stats_params))) == NULL)
+		return (ENOMEM);
+
+	if (name != NULL) {
+		/*
+		 * Allow VMs names with alphanumeric characters, dot, hyphen
+		 * and underscore. But disallow dot, hyphen and underscore at
+		 * the start.
+		 */
+		if (*name == '-' || *name == '.' || *name == '_')
+			errx(1, "invalid VM name");
+
+		for (s = name; *s != '\0'; ++s) {
+			if (!(isalnum(*s) || *s == '.' || *s == '-' ||
+			    *s == '_'))
+				errx(1, "invalid VM name");
+		}
+
+		if (strlcpy(vsp->vsp_name, name,
+		    sizeof(vsp->vsp_name)) >= sizeof(vsp->vsp_name))
+			errx(1, "vm name too long");
+	}
+
+	vsp->vsp_id = vm_id;
+
+	imsg_compose(ibuf, IMSG_VMDOP_STATS_VM_REQUEST, 0, 0, -1,
+	    vsp, sizeof(struct vmop_stats_params));
+
+	free(vsp);
+
+	return (0);
+}
+
+int
+vm_stats_complete(struct imsg *imsg, int *ret)
+{
+	struct vmop_result *vmr;
+	int res;
+
+	if (imsg->hdr.type == IMSG_VMDOP_STATS_VM_RESPONSE) {
+		vmr = (struct vmop_result *)imsg->data;
+		res = vmr->vmr_result;
+		if (res) {
+			errno = res;
+			warn("stats vm command failed");
+			*ret = EIO;
+		} else {
+			warnx("getting stats from vm %d successfully",
+			    vmr->vmr_id);
+			*ret = 0;
+		}
+	} else {
+		warnx("unexpected response received from vmd");
+		*ret = EINVAL;
+	}
+
+	return (1);
+}
+
 /*
  * vm_start
  *
@@ -153,6 +284,7 @@ vm_start(uint32_t start_id, const char *name, int memsize, int nnics,
 				errx(1, "interface name too long");
 		}
 	}
+
 	if (name != NULL) {
 		/*
 		 * Allow VMs names with alphanumeric characters, dot, hyphen
@@ -459,7 +591,7 @@ terminate_vm(uint32_t terminate_id, const char *name, unsigned int flags)
  * terminate_vm_complete
  *
  * Callback function invoked when we are expecting an
- * IMSG_VMDOP_TERMINATE_VMM_RESPONSE message indicating the completion of
+ * IMSG_VMDOP_TERMINATE_VM_RESPONSE message indicating the completion of
  * a terminate vm operation.
  *
  * Parameters:
@@ -716,6 +848,8 @@ vm_state(unsigned int mask)
 {
 	if (mask & VM_STATE_PAUSED)
 		return "paused";
+	else if (mask & VM_STATE_WAITING)
+		return "waiting";
 	else if (mask & VM_STATE_RUNNING)
 		return "running";
 	else if (mask & VM_STATE_SHUTDOWN)
@@ -744,13 +878,14 @@ print_vm_info(struct vmop_info_result *list, size_t ct)
 	size_t i;
 	char *tty;
 	char curmem[FMT_SCALED_STRSIZE];
+	char swap[FMT_SCALED_STRSIZE];
 	char maxmem[FMT_SCALED_STRSIZE];
 	char user[16], group[16];
 	const char *name;
 	int running;
 
-	printf("%5s %5s %5s %7s %7s %7s %12s %8s %s\n", "ID", "PID", "VCPUS",
-	    "MAXMEM", "CURMEM", "TTY", "OWNER", "STATE", "NAME");
+	printf("%5s %5s %5s %7s %7s %7s %7s %12s %8s %s\n", "ID", "PID", "VCPUS",
+	    "MAXMEM", "CURMEM", "SWAP", "TTY", "OWNER", "STATE", "NAME");
 
 	for (i = 0; i < ct; i++) {
 		vmi = &list[i];
@@ -766,8 +901,6 @@ print_vm_info(struct vmop_info_result *list, size_t ct)
 				(void)strlcpy(user, name, sizeof(user));
 			/* get group name */
 			if (vmi->vir_gid != -1) {
-				if (vmi->vir_uid == 0)
-					*user = '\0';
 				name = group_from_gid(vmi->vir_gid, 1);
 				if (name == NULL)
 					(void)snprintf(group, sizeof(group),
@@ -780,6 +913,7 @@ print_vm_info(struct vmop_info_result *list, size_t ct)
 
 			(void)strlcpy(curmem, "-", sizeof(curmem));
 			(void)strlcpy(maxmem, "-", sizeof(maxmem));
+			(void)strlcpy(swap, "-", sizeof(swap));
 
 			(void)fmt_scaled(vir->vir_memory_size * 1024 * 1024,
 			    maxmem);
@@ -793,18 +927,20 @@ print_vm_info(struct vmop_info_result *list, size_t ct)
 					tty = list[i].vir_ttyname;
 
 				(void)fmt_scaled(vir->vir_used_size, curmem);
+				/* Needs mult by 4k XXX */
+				(void)fmt_scaled(vir->vir_swpginuse, swap);
 
 				/* running vm */
-				printf("%5u %5u %5zd %7s %7s %7s %12s %8s %s\n",
+				printf("%5u %5u %5zd %7s %7s %7s %7s %12s %8s %s\n",
 				    vir->vir_id, vir->vir_creator_pid,
-				    vir->vir_ncpus, maxmem, curmem,
+				    vir->vir_ncpus, maxmem, curmem, swap,
 				    tty, user, vm_state(vmi->vir_state),
 				    vir->vir_name);
 			} else {
 				/* disabled vm */
-				printf("%5u %5s %5zd %7s %7s %7s %12s %8s %s\n",
+				printf("%5u %5s %5zd %7s %7s %7s %7s %12s %8s %s\n",
 				    vir->vir_id, "-",
-				    vir->vir_ncpus, maxmem, curmem,
+				    vir->vir_ncpus, maxmem, curmem, swap,
 				    "-", user, vm_state(vmi->vir_state),
 				    vir->vir_name);
 			}
@@ -949,4 +1085,3 @@ create_imagefile(int type, const char *imgfile_path, const char *base_path,
 
 	return (ret);
 }
-
diff --git a/usr.sbin/vmctl/main.c b/usr.sbin/vmctl/main.c
index 3eb89c9fe96..0065d77e6c1 100644
--- a/usr.sbin/vmctl/main.c
+++ b/usr.sbin/vmctl/main.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: main.c,v 1.58 2019/08/23 07:55:20 mlarkin Exp $	*/
+/*	$OpenBSD: main.c,v 1.62 2020/01/03 05:32:00 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Reyk Floeter <reyk@openbsd.org>
@@ -45,8 +45,8 @@
 #define QCOW2_FMT	"qcow2"
 
 static const char	*socket_name = SOCKET_NAME;
-static int		 ctl_sock = -1;
-static int		 tty_autoconnect = 0;
+static int		 	ctl_sock = -1;
+static int		 	tty_autoconnect = 0;
 
 __dead void	 usage(void);
 __dead void	 ctl_usage(struct ctl_command *);
@@ -68,6 +68,8 @@ int		 ctl_pause(struct parse_result *, int, char *[]);
 int		 ctl_unpause(struct parse_result *, int, char *[]);
 int		 ctl_send(struct parse_result *, int, char *[]);
 int		 ctl_receive(struct parse_result *, int, char *[]);
+int		 ctl_balloon(struct parse_result *, int, char *[]);
+int		 ctl_stats(struct parse_result *, int, char *[]);
 
 struct ctl_command ctl_commands[] = {
 	{ "console",	CMD_CONSOLE,	ctl_console,	"id" },
@@ -88,6 +90,8 @@ struct ctl_command ctl_commands[] = {
 	{ "stop",	CMD_STOP,	ctl_stop,	"[-fw] [id | -a]" },
 	{ "unpause",	CMD_UNPAUSE,	ctl_unpause,	"id" },
 	{ "wait",	CMD_WAITFOR,	ctl_waitfor,	"id" },
+	{ "balloon",	CMD_BALLOON,	ctl_balloon,	"[-m size] [-d] id" },
+	{ "stats",	CMD_STATS,	ctl_stats,	"id" },
 	{ NULL }
 };
 
@@ -265,10 +269,25 @@ vmmaction(struct parse_result *res)
 	case CMD_SEND:
 		send_vm(res->id, res->name);
 		done = 1;
+		ret = 0;
 		break;
 	case CMD_RECEIVE:
 		vm_receive(res->id, res->name);
 		break;
+	case CMD_BALLOON:
+		ret = vm_balloon(res->id, res->name, res->size);
+		if (ret) {
+			errno = ret;
+			err(1, "balloon operation failed");
+		}
+		break;
+	case CMD_STATS:
+		ret = vm_stats(res->id, res->name);
+		if (ret) {
+			errno = ret;
+			err(1, "stats operation failed");
+		}
+		break;
 	case CMD_CREATE:
 	case NONE:
 		/* The action is not expected here */
@@ -336,6 +355,12 @@ vmmaction(struct parse_result *res)
 			case CMD_UNPAUSE:
 				done = unpause_vm_complete(&imsg, &ret);
 				break;
+			case CMD_BALLOON:
+				done = vm_balloon_complete(&imsg, &ret);
+				break;
+			case CMD_STATS:
+				done = vm_stats_complete(&imsg, &ret);
+				break;
 			default:
 				done = 1;
 				break;
@@ -373,9 +398,9 @@ parse_ifs(struct parse_result *res, char *word, int val)
 	const char	*error;
 
 	if (word != NULL) {
-		val = strtonum(word, 0, INT_MAX, &error);
+		val = strtonum(word, 1, INT_MAX, &error);
 		if (error != NULL)  {
-			warnx("invalid count \"%s\": %s", word, error);
+			warnx("count is %s: %s", error, word);
 			return (-1);
 		}
 	}
@@ -407,8 +432,10 @@ parse_network(struct parse_result *res, char *word)
 }
 
 int
-parse_size(struct parse_result *res, char *word, long long val)
+parse_size(struct parse_result *res, char *word)
 {
+	long long val = 0;
+
 	if (word != NULL) {
 		if (scan_scaled(word, &val) != 0) {
 			warn("invalid size: %s", word);
@@ -576,7 +603,7 @@ ctl_create(struct parse_result *res, int argc, char *argv[])
 				err(1, "unveil");
 			break;
 		case 's':
-			if (parse_size(res, optarg, 0) != 0)
+			if (parse_size(res, optarg) != 0)
 				errx(1, "invalid size: %s", optarg);
 			break;
 		default:
@@ -872,7 +899,7 @@ ctl_start(struct parse_result *res, int argc, char *argv[])
 		case 'm':
 			if (res->size)
 				errx(1, "memory specified multiple times");
-			if (parse_size(res, optarg, 0) != 0)
+			if (parse_size(res, optarg) != 0)
 				errx(1, "invalid memory size: %s", optarg);
 			break;
 		case 'n':
@@ -1045,6 +1072,52 @@ ctl_openconsole(const char *name)
 	closefrom(STDERR_FILENO + 1);
 	if (unveil(VMCTL_CU, "x") == -1)
 		err(1, "unveil");
-	execl(VMCTL_CU, VMCTL_CU, "-l", name, "-s", "115200", (char *)NULL);
+	execl(VMCTL_CU, VMCTL_CU, "-r", "-l", name, "-s", "115200",
+	    (char *)NULL);
 	err(1, "failed to open the console");
 }
+
+int
+ctl_balloon(struct parse_result *res, int argc, char *argv[])
+{
+	int ch;
+
+	while ((ch = getopt(argc, argv, "m:d")) != -1) {
+		switch (ch) {
+		case 'm':
+			if (res->size)
+				errx(1, "memory specified multiple times");
+			if (parse_size(res, optarg) != 0)
+				errx(1, "invalid memory size: %s", optarg);
+			break;
+		case 'd':
+			res->size = 0;
+			break;
+		default:
+			ctl_usage(res->ctl);
+			/* NOTREACHED */
+		}
+	}
+	argc -= optind;
+	argv += optind;
+
+	if (argc != 1)
+		ctl_usage(res->ctl);
+
+	if (parse_vmid(res, argv[0], 0) == -1)
+		errx(1, "invalid id: %s", argv[1]);
+
+	return (vmmaction(res));
+}
+
+int
+ctl_stats(struct parse_result *res, int argc, char *argv[])
+{
+	if (argc == 2) {
+		if (parse_vmid(res, argv[1], 0) == -1)
+			errx(1, "invalid id: %s", argv[1]);
+	} else if (argc != 2)
+		ctl_usage(res->ctl);
+
+	return (vmmaction(res));
+}
diff --git a/usr.sbin/vmctl/vmctl.h b/usr.sbin/vmctl/vmctl.h
index e20ce1a43d4..afb541e5604 100644
--- a/usr.sbin/vmctl/vmctl.h
+++ b/usr.sbin/vmctl/vmctl.h
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmctl.h,v 1.32 2019/05/11 23:07:46 jasper Exp $	*/
+/*	$OpenBSD: vmctl.h,v 1.33 2019/12/17 09:43:00 kn Exp $	*/
 
 /*
  * Copyright (c) 2015 Reyk Floeter <reyk@openbsd.org>
@@ -38,6 +38,8 @@ enum actions {
 	CMD_UNPAUSE,
 	CMD_SEND,
 	CMD_RECEIVE,
+	CMD_BALLOON,
+	CMD_STATS
 };
 
 struct ctl_command;
@@ -72,12 +74,14 @@ struct ctl_command {
 };
 
 struct imsgbuf	*ibuf;
+static int 		vm_counter = 0;
 
 /* main.c */
 int	 vmmaction(struct parse_result *);
 int	 parse_ifs(struct parse_result *, char *, int);
 int	 parse_network(struct parse_result *, char *);
-int	 parse_size(struct parse_result *, char *, long long);
+int	 parse_size(struct parse_result *, char *);
+int	 parse_size_balloon(struct parse_result *, char *);
 int	 parse_disktype(const char *, const char **);
 int	 parse_disk(struct parse_result *, char *, int);
 int	 parse_vmid(struct parse_result *, char *, int);
@@ -105,6 +109,10 @@ void	 unpause_vm(uint32_t, const char *);
 int	 unpause_vm_complete(struct imsg *, int *);
 void	 send_vm(uint32_t, const char *);
 void	 vm_receive(uint32_t, const char *);
+int	 vm_balloon(uint32_t, const char *, int);
+int	 vm_balloon_complete(struct imsg *, int *);
+int	 vm_stats(uint32_t, const char *);
+int	 vm_stats_complete(struct imsg *, int *);
 int	 check_info_id(const char *, uint32_t);
 void	 get_info_vm(uint32_t, const char *, enum actions, unsigned int);
 int	 add_info(struct imsg *, int *);
@@ -114,5 +122,6 @@ void	 print_vm_info(struct vmop_info_result *, size_t);
 void	 terminate_all(struct vmop_info_result *, size_t, unsigned int);
 __dead void
 	 vm_console(struct vmop_info_result *, size_t);
+void get_num_vm(struct imsg *imsg, int *ret);
 
 #endif /* VMCTL_PARSER_H */
diff --git a/usr.sbin/vmd/virtio.h b/usr.sbin/vmd/virtio.h
index f0a5513ab51..020c7e91e46 100644
--- a/usr.sbin/vmd/virtio.h
+++ b/usr.sbin/vmd/virtio.h
@@ -1,4 +1,4 @@
-/*	$OpenBSD: virtio.h,v 1.34 2018/12/06 09:20:06 claudio Exp $	*/
+/*	$OpenBSD: virtio.h,v 1.35 2019/12/11 06:45:16 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Mike Larkin <mlarkin@openbsd.org>
@@ -36,6 +36,9 @@
 #define VIONET_QUEUE_SIZE	256
 #define VIONET_QUEUE_MASK	(VIONET_QUEUE_SIZE - 1)
 
+#define VIOMBH_QUEUE_SIZE	64
+#define VIOMBH_QUEUE_MASK	(VIOMBH_QUEUE_SIZE - 1)
+
 /* VMM Control Interface shutdown timeout (in seconds) */
 #define VMMCI_TIMEOUT		3
 #define VMMCI_SHUTDOWN_TIMEOUT	30
@@ -45,9 +48,23 @@
  * vioblk - 1 queue
  * vionet - 2 queues
  * vioscsi - 3 queues
+ * viomb - 3 queues
  */
 #define VIRTIO_MAX_QUEUES	3
 
+#define VIRTIO_BALLOON_F_MUST_TELL_HOST 0
+#define VIRTIO_BALLOON_F_STATS_VQ	    1 /* Memory Stats virtqueue */
+#define VIRTIO_BALLOON_F_DEFLATE_ON_OOM	2
+
+#define VIRTIO_BALLOON_S_SWAP_IN  0   /* Amount of memory swapped in */
+#define VIRTIO_BALLOON_S_SWAP_OUT 1   /* Amount of memory swapped out */
+#define VIRTIO_BALLOON_S_MAJFLT   2   /* Number of major faults */
+#define VIRTIO_BALLOON_S_MINFLT   3   /* Number of minor faults */
+#define VIRTIO_BALLOON_S_MEMFREE  4   /* Total amount of free memory */
+#define VIRTIO_BALLOON_S_MEMTOT   5   /* Total amount of memory */
+#define VIRTIO_BALLOON_S_AVAIL    6   /* not used */
+#define VIRTIO_BALLOON_S_NR       7   /* not used */
+
 /*
  * This struct stores notifications from a virtio driver. There is
  * one such struct per virtio device.
@@ -142,6 +159,19 @@ struct virtio_vq_acct {
 	struct vring_used *used;
 };
 
+struct viombh_dev {
+	struct virtio_io_cfg cfg;
+
+	struct virtio_vq_info vq[VIRTIO_MAX_QUEUES];
+
+	uint8_t pci_id;
+	int irq;
+	uint32_t vm_id;
+
+	uint32_t num_pages;
+	uint32_t actual;
+};
+
 struct viornd_dev {
 	struct virtio_io_cfg cfg;
 
@@ -259,6 +289,11 @@ struct ioinfo {
 	int error;
 };
 
+struct virtio_balloon_stat {
+	uint16_t tag;
+	uint64_t val;
+} __attribute__((packed));
+
 /* virtio.c */
 void virtio_init(struct vmd_vm *, int, int[][VM_MAX_BASE_PER_DISK], int *);
 void virtio_shutdown(struct vmd_vm *);
@@ -318,3 +353,14 @@ int vioscsi_io(int, uint16_t, uint32_t *, uint8_t *, void *, uint8_t);
 void vioscsi_update_qs(struct vioscsi_dev *);
 void vioscsi_update_qa(struct vioscsi_dev *);
 int vioscsi_notifyq(struct vioscsi_dev *);
+void virtio_stop(struct vm_create_params *);
+void virtio_start(struct vm_create_params *);
+
+int virtio_mbh_io(int, uint16_t, uint32_t *, uint8_t *, void *, uint8_t);
+void viombh_update_qs(void);
+void viombh_update_qa(void);
+int viombh_notifyq(void);
+int viombh_restore(int, struct vm_create_params *);
+int viombh_dump(int);
+void balloon_vm(struct vmd_vm *, uint32_t size);
+void stats_vm(struct vmd_vm *);
diff --git a/usr.sbin/vmd/virtio.c b/usr.sbin/vmd/virtio.c
index 9bd120f0bd3..0f6874bb51a 100644
--- a/usr.sbin/vmd/virtio.c
+++ b/usr.sbin/vmd/virtio.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: virtio.c,v 1.79 2019/09/24 12:14:54 mlarkin Exp $	*/
+/*	$OpenBSD: virtio.c,v 1.82 2019/12/11 06:45:16 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Mike Larkin <mlarkin@openbsd.org>
@@ -18,6 +18,7 @@
 
 #include <sys/param.h>	/* PAGE_SIZE */
 #include <sys/socket.h>
+#include <sys/ioctl.h>
 
 #include <machine/vmmvar.h>
 #include <dev/pci/pcireg.h>
@@ -27,6 +28,8 @@
 #include <dev/pv/vioblkreg.h>
 #include <dev/pv/vioscsireg.h>
 
+#include <uvm/uvm_extern.h>
+
 #include <net/if.h>
 #include <netinet/in.h>
 #include <netinet/if_ether.h>
@@ -48,16 +51,18 @@
 #include "atomicio.h"
 
 extern char *__progname;
-
 struct viornd_dev viornd;
 struct vioblk_dev *vioblk;
 struct vionet_dev *vionet;
 struct vioscsi_dev *vioscsi;
 struct vmmci_dev vmmci;
+struct viombh_dev viombh;
 
 int nr_vionet;
 int nr_vioblk;
 
+extern struct vmd *env;
+
 #define MAXPHYS	(64 * 1024)	/* max raw I/O transfer size */
 
 #define VIRTIO_NET_F_MAC	(1<<5)
@@ -121,7 +126,13 @@ virtio_reg_name(uint8_t reg)
 	case VIRTIO_CONFIG_DEVICE_STATUS: return "device status";
 	case VIRTIO_CONFIG_ISR_STATUS: return "isr status";
 	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI: return "device config 0";
+	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 1: return "device config 0[1]";
+	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 2: return "device config 0[2]";
+	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 3: return "device config 0[3]";
 	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 4: return "device config 1";
+	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 5: return "device config 1[1]";
+	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 6: return "device config 1[2]";
+	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 7: return "device config 1[3]";
 	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 8: return "device config 2";
 	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 12: return "device config 3";
 	case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 16: return "device config 4";
@@ -144,6 +155,456 @@ vring_size(uint32_t vq_size)
 	return allocsize1 + allocsize2;
 }
 
+void
+viombh_update_qs(void)
+{
+	/* Invalid queue? */
+	if (viombh.cfg.queue_select > 2) {
+		viombh.cfg.queue_size = 0;
+		return;
+	}
+
+	/* Update queue address/size based on queue select */
+	viombh.cfg.queue_address = viombh.vq[viombh.cfg.queue_select].qa;
+	viombh.cfg.queue_size = viombh.vq[viombh.cfg.queue_select].qs;
+}
+
+void
+viombh_update_qa(void)
+{
+	/* Invalid queue? */
+	if (viombh.cfg.queue_select > 2)
+		return;
+
+	viombh.vq[viombh.cfg.queue_select].qa = viombh.cfg.queue_address;
+}
+
+int
+viombh_notifyq(void)
+{
+	uint64_t q_gpa;
+	uint32_t vr_sz;
+	size_t sz;
+	int ret;
+	uint32_t i;
+	uint32_t *buf_bl_pages;
+	struct virtio_balloon_stat *buf_bl_stats;
+	uint16_t aidx, uidx;
+	char *buf;
+	struct vring_desc *desc;
+	struct vring_avail *avail;
+	struct vring_used *used;
+	struct vm_inflate_balloon_params vibp;
+
+	ret = 0;
+
+	/* Invalid queue? */
+	if (viombh.cfg.queue_notify > 2)
+		return (0);
+
+	vr_sz = vring_size(VIOMBH_QUEUE_SIZE);
+	q_gpa = viombh.vq[viombh.cfg.queue_notify].qa;
+	q_gpa = q_gpa * VIRTIO_PAGE_SIZE;
+
+	buf = calloc(1, vr_sz);
+	if (buf == NULL) {
+		log_warn("calloc error getting viombh ring");
+		return (0);
+	}
+
+	if (read_mem(q_gpa, buf, vr_sz)) {
+		free(buf);
+		return (0);
+	}
+
+	desc = (struct vring_desc *)(buf);
+	avail = (struct vring_avail *)(buf +
+	    viombh.vq[viombh.cfg.queue_notify].vq_availoffset);
+	used = (struct vring_used *)(buf +
+	    viombh.vq[viombh.cfg.queue_notify].vq_usedoffset);
+
+	aidx = avail->idx & VIOMBH_QUEUE_MASK;
+	uidx = used->idx & VIOMBH_QUEUE_MASK;
+
+	sz = desc[avail->ring[aidx]].len;
+
+	printf("%s: being called for %d queue\n", __func__, viombh.cfg.queue_notify);
+
+	/* Inflate queue */
+	if (viombh.cfg.queue_notify == 0)
+	{
+		buf_bl_pages = calloc(1, sz);
+
+		if (read_mem(desc[avail->ring[aidx]].addr, buf_bl_pages, sz)) {
+			printf("error from %s", __func__);
+			free(buf_bl_pages);
+			goto out;
+		}
+
+		memset(&vibp, 0, sizeof(vibp));
+
+		for (i = 0; i < (sz / 4); i++) {
+			log_debug("%s: got page number 0x%llx from vm for "
+			    "inflate %d/%llu", __func__,
+			    (uint64_t)buf_bl_pages[i],
+			    i, (uint64_t)(sz / 4));
+			vibp.vibp_buf_bl_pages[i] = (uint64_t)buf_bl_pages[i];
+		}
+
+		vibp.vibp_bl_pages_sz = sz/4;
+		vibp.vibp_vm_id = viombh.vm_id;
+
+		/* Instruct vmm(4) to inflate the balloon and reclaim the pages */
+		if (ioctl(env->vmd_fd, VMM_IOC_BALLOON_INFLATE, &vibp) == -1) {
+			log_warn("balloon inflate ioctl failed: %s",
+				strerror(errno));
+			free(buf_bl_pages);
+			goto out;
+		}
+
+		ret = 1;
+		viombh.cfg.isr_status = 1;
+		used->ring[uidx].id = avail->ring[aidx] & VIOMBH_QUEUE_MASK;
+		used->ring[uidx].len = desc[avail->ring[aidx]].len;
+		used->idx++;
+
+		if (write_mem(q_gpa, buf, vr_sz)) {
+			log_warnx("viombh: error writing vio ring");
+		}
+
+		free(buf_bl_pages);
+	}
+	/* Deflate queue */
+	else if (viombh.cfg.queue_notify == 1)
+	{
+		/* Nothing to do in the deflate case, just advance the ring */
+		ret = 1;
+		viombh.cfg.isr_status = 1;
+		used->ring[uidx].id = avail->ring[aidx] & VIOMBH_QUEUE_MASK;
+		used->ring[uidx].len = desc[avail->ring[aidx]].len;
+		used->idx++;
+
+		if (write_mem(q_gpa, buf, vr_sz)) {
+			log_warnx("viombh: error writing vio ring");
+		}
+
+		printf("%s:memory balloon is deflated successfully\n",__func__);
+
+	}
+	/* Stats queue */
+	else if (viombh.cfg.queue_notify == 2)
+	{
+		printf("%s: stats queue is notified\n",__func__);
+		buf_bl_stats = calloc(1, sz);
+
+		if (read_mem(desc[avail->ring[aidx]].addr, buf_bl_stats, sz)) {
+			printf("error from %s", __func__);
+			free(buf_bl_stats);
+			goto out;
+		}
+
+		sz = sz/(sizeof(struct virtio_balloon_stat));
+
+		for (i = 0; i < sz; i++) {
+			switch (i) {
+				case 0: printf("%s: stats[%d] for Swap pages in use: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+				case 1: printf("%s: stats[%d] for Pages swapped out: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+				case 2: printf("%s: stats[%d] for Faults: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+				case 3: printf("%s: stats[%d] for Free pages: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+				case 4: printf("%s: stats[%d] for Num pages: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+				case 5: printf("%s: stats[%d] for Number of Buffered Pages: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+				default: printf("%s: stats[%d]: tag=0x%x val=0x%llx\n", __func__, i,
+							buf_bl_stats[i].tag, buf_bl_stats[i].val);
+					break;
+
+			}
+		}
+		printf("%s: leaving\n", __func__);
+		free(buf_bl_stats);
+	}
+
+out:
+	free(buf);
+	return (ret);
+}
+
+int
+virtio_mbh_io(int dir, uint16_t reg, uint32_t *data, uint8_t *intr,
+    void *unused, uint8_t sz)
+{
+	*intr = 0xFF;
+
+	printf("%s: reg: %u size: %u\n", __func__, reg, sz);
+
+	/* Write */
+	if (dir == 0) {
+		switch (reg) {
+		case VIRTIO_CONFIG_DEVICE_FEATURES:
+		case VIRTIO_CONFIG_QUEUE_SIZE:
+		case VIRTIO_CONFIG_ISR_STATUS:
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI:
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 1:
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 2:
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 3:
+			log_warnx("%s: illegal write %x to %s",
+			    __progname, *data, virtio_reg_name(reg));
+			break;
+		case VIRTIO_CONFIG_GUEST_FEATURES:
+			viombh.cfg.guest_feature = *data;
+			break;
+		case VIRTIO_CONFIG_QUEUE_ADDRESS:
+			viombh.cfg.queue_address = *data;
+			viombh_update_qa();
+			break;
+		case VIRTIO_CONFIG_QUEUE_SELECT:
+			viombh.cfg.queue_select = *data;
+			viombh_update_qs();
+			break;
+		case VIRTIO_CONFIG_QUEUE_NOTIFY:
+			viombh.cfg.queue_notify = *data;
+			if (viombh_notifyq())
+				*intr = 1;
+			break;
+		case VIRTIO_CONFIG_DEVICE_STATUS:
+			viombh.cfg.device_status = *data;
+			if (viombh.cfg.device_status == 0) {
+				log_debug("%s: device reset", __func__);
+				viombh.cfg.guest_feature = 0;
+				viombh.cfg.queue_address = 0;
+				viombh_update_qa();
+				viombh.cfg.queue_size = 0;
+				viombh_update_qs();
+				viombh.cfg.queue_select = 0;
+				viombh.cfg.queue_notify = 0;
+				viombh.cfg.isr_status = 0;
+				viombh.vq[0].last_avail = 0;
+				viombh.vq[1].last_avail = 0;
+				viombh.vq[2].last_avail = 0;
+				viombh.num_pages = 0;
+				viombh.actual = 0;
+				vcpu_deassert_pic_irq(viombh.vm_id, 0, viombh.irq);
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 4:
+			switch (sz) {
+			case 4:
+				viombh.actual = (uint32_t)(*data);
+				break;
+			case 2:
+				viombh.actual &= 0xFFFF0000;
+				viombh.actual |= (uint32_t)(*data) & 0xFFFF;
+				break;
+			case 1:
+				viombh.actual &= 0xFFFFFF00;
+				viombh.actual |= (uint32_t)(*data) & 0xFF;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 5:
+			switch (sz) {
+			case 1:
+				viombh.actual &= 0xFFFF00FF;
+				viombh.actual |= ((uint32_t)(*data) & 0xFF) << 8;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 6:
+			switch (sz) {
+			case 1:
+				viombh.actual &= 0xFF00FFFF;
+				viombh.actual |= ((uint32_t)(*data) & 0xFF) << 16;
+				break;
+			case 2:
+				viombh.actual &= 0x0000FFFF;
+				viombh.actual |= ((uint32_t)(*data) & 0xFFFF) << 16;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 7:
+			switch (sz) {
+			case 1:
+				viombh.actual &= 0x00FFFFFF;
+				viombh.actual |= ((uint32_t)(*data) & 0xFF) << 24;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		}
+	} else {
+		switch (reg) {
+		case VIRTIO_CONFIG_DEVICE_FEATURES:
+			*data = viombh.cfg.device_feature;
+			break;
+		case VIRTIO_CONFIG_GUEST_FEATURES:
+			*data = viombh.cfg.guest_feature;
+			break;
+		case VIRTIO_CONFIG_QUEUE_ADDRESS:
+			*data = viombh.cfg.queue_address;
+			break;
+		case VIRTIO_CONFIG_QUEUE_SIZE:
+			*data = viombh.cfg.queue_size;
+			break;
+		case VIRTIO_CONFIG_QUEUE_SELECT:
+			*data = viombh.cfg.queue_select;
+			break;
+		case VIRTIO_CONFIG_QUEUE_NOTIFY:
+			*data = viombh.cfg.queue_notify;
+			break;
+		case VIRTIO_CONFIG_DEVICE_STATUS:
+			*data = viombh.cfg.device_status;
+			break;
+		case VIRTIO_CONFIG_ISR_STATUS:
+			*data = viombh.cfg.isr_status;
+			viombh.cfg.isr_status = 0;
+			vcpu_deassert_pic_irq(viombh.vm_id, 0, viombh.irq);
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI:
+			switch (sz) {
+			case 4:
+				*data = (uint32_t)(viombh.num_pages);
+				break;
+			case 2:
+				*data &= 0xFFFF0000;
+				*data |= (uint32_t)(viombh.num_pages) & 0xFFFF;
+				break;
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= (uint32_t)(viombh.num_pages) & 0xFF;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 1:
+			switch (sz) {
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= ((uint32_t)(viombh.num_pages) &
+				     0xFF00) >> 8;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 2:
+			switch (sz) {
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= ((uint32_t)(viombh.num_pages) &
+				     0xFF0000) >> 16;
+				break;
+			case 2:
+				*data &= 0xFFFF0000;
+				*data |= ((uint32_t)(viombh.num_pages) &
+				     0xFFFF0000) >> 16;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 3:
+			switch (sz) {
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= ((uint32_t)(viombh.num_pages) &
+				     0xFF000000) >> 24;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 4:
+			switch (sz) {
+			case 4:
+				*data = (uint32_t)(viombh.actual);
+				break;
+			case 2:
+				*data &= 0xFFFF0000;
+				*data |= (uint32_t)(viombh.actual) & 0xFFFF;
+				break;
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= (uint32_t)(viombh.actual) & 0xFF;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 5:
+			switch (sz) {
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= ((uint32_t)(viombh.actual) &
+				     0xFF00) >> 8;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 6:
+			switch (sz) {
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= ((uint32_t)(viombh.actual) &
+				     0xFF0000) >> 16;
+				break;
+			case 2:
+				*data &= 0xFFFF0000;
+				*data |= ((uint32_t)(viombh.actual) &
+				     0xFFFF0000) >> 16;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		case VIRTIO_CONFIG_DEVICE_CONFIG_NOMSI + 7:
+			switch (sz) {
+			case 1:
+				*data &= 0xFFFFFF00;
+				*data |= ((uint32_t)(viombh.actual) &
+				     0xFF000000) >> 24;
+				break;
+			default:
+				/* XXX handle invalid sz */
+				break;
+			}
+			break;
+		}
+	}
+
+	return (0);
+}
+
 /* Update queue select */
 void
 viornd_update_qs(void)
@@ -2026,23 +2487,6 @@ virtio_init(struct vmd_vm *vm, int child_cdrom,
 		return;
 	}
 
-	/* virtio memory balloon device */
-	if (pci_add_device(&id, PCI_VENDOR_QUMRANET,
-	    PCI_PRODUCT_QUMRANET_VIO_MEM, PCI_CLASS_SYSTEM,
-	    PCI_SUBCLASS_SYSTEM_MISC,
-	    PCI_VENDOR_OPENBSD,
-	    PCI_PRODUCT_VIRTIO_BALLOON, 1, NULL)) {
-		log_warnx("%s: can't add PCI virtio mem device",
-		    __progname);
-		return;
-	}
-
-	if (pci_add_bar(id, PCI_MAPREG_TYPE_IO, NULL, NULL)) {
-		log_warnx("%s: can't add bar for virtio mem device",
-		    __progname);
-		return;
-	}
-
 	memset(&vmmci, 0, sizeof(vmmci));
 	vmmci.cfg.device_feature = VMMCI_F_TIMESYNC | VMMCI_F_ACK |
 	    VMMCI_F_SYNCRTC;
@@ -2051,6 +2495,49 @@ virtio_init(struct vmd_vm *vm, int child_cdrom,
 	vmmci.pci_id = id;
 
 	evtimer_set(&vmmci.timeout, vmmci_timeout, NULL);
+
+	if (pci_add_device(
+            &id, PCI_VENDOR_QUMRANET,
+            PCI_PRODUCT_QUMRANET_VIO_MEM,
+            PCI_CLASS_SYSTEM,
+            PCI_SUBCLASS_SYSTEM_MISC,
+            PCI_VENDOR_OPENBSD,
+            PCI_PRODUCT_VIRTIO_BALLOON,
+            1,
+            NULL)) {
+		log_warnx("%s: can't add PCI virtio memory balloon device",
+		__progname);
+		return;
+	}
+
+	if (pci_add_bar(id, PCI_MAPREG_TYPE_IO,
+	    virtio_mbh_io, NULL)) {
+		log_warnx("%s: can't add bar for virtio memory balloon device",
+		    __progname);
+		return;
+	}
+
+
+	memset(&viombh, 0, sizeof(viombh));
+	viombh.vq[0].qs = VIOMBH_QUEUE_SIZE;
+	viombh.vq[0].vq_availoffset = sizeof(struct vring_desc) * VIOMBH_QUEUE_SIZE;
+	viombh.vq[0].vq_usedoffset = VIRTQUEUE_ALIGN(sizeof(struct vring_desc) *
+		VIOMBH_QUEUE_SIZE + sizeof(uint16_t) * (2 + VIOMBH_QUEUE_SIZE));
+	viombh.vq[0].last_avail = 0;
+	viombh.vq[1].qs = VIOMBH_QUEUE_SIZE;
+	viombh.vq[1].vq_availoffset = sizeof(struct vring_desc) * VIOMBH_QUEUE_SIZE;
+	viombh.vq[1].vq_usedoffset = VIRTQUEUE_ALIGN(sizeof(struct vring_desc) *
+		VIOMBH_QUEUE_SIZE + sizeof(uint16_t) * (2 + VIOMBH_QUEUE_SIZE));
+	viombh.vq[1].last_avail = 0;
+	viombh.vq[2].qs = VIOMBH_QUEUE_SIZE;
+	viombh.vq[2].vq_availoffset = sizeof(struct vring_desc) * VIOMBH_QUEUE_SIZE;
+	viombh.vq[2].vq_usedoffset = VIRTQUEUE_ALIGN(sizeof(struct vring_desc) *
+		VIOMBH_QUEUE_SIZE + sizeof(uint16_t) * (2 + VIOMBH_QUEUE_SIZE));
+	viombh.vq[2].last_avail = 0;
+	viombh.pci_id = id;
+	viombh.irq = pci_get_dev_irq(id);
+	viombh.vm_id = vcp->vcp_id;
+	viombh.cfg.device_feature = VIRTIO_BALLOON_F_STATS_VQ;
 }
 
 void
@@ -2087,6 +2574,25 @@ vmmci_restore(int fd, uint32_t vm_id)
 	return (0);
 }
 
+int
+viombh_restore(int fd, struct vm_create_params *vcp)
+{
+	log_debug("%s: receiving viombh", __func__);
+	if (atomicio(read, fd, &viombh, sizeof(viombh)) != sizeof(viombh)) {
+		log_warnx("%s: error reading viombh from fd", __func__);
+		return (-1);
+	}
+	if (pci_set_bar_fn(viombh.pci_id, 0, virtio_mbh_io, NULL)) {
+		log_warnx("%s: can't set bar fn for virtio mem balloon device",
+		    __progname);
+		return (-1);
+	}
+	viombh.vm_id = vcp->vcp_id;
+	viombh.irq = pci_get_dev_irq(viombh.pci_id);
+
+	return (0);
+}
+
 int
 viornd_restore(int fd, struct vm_create_params *vcp)
 {
@@ -2158,11 +2664,6 @@ vionet_restore(int fd, struct vmd_vm *vm, int *child_taps)
 			memset(&vionet[i].event, 0, sizeof(struct event));
 			event_set(&vionet[i].event, vionet[i].fd,
 			    EV_READ | EV_PERSIST, vionet_rx_event, &vionet[i]);
-			if (event_add(&vionet[i].event, NULL)) {
-				log_warn("could not initialize vionet event "
-				    "handler");
-				return (-1);
-			}
 		}
 	}
 	return (0);
@@ -2268,6 +2769,9 @@ virtio_restore(int fd, struct vmd_vm *vm, int child_cdrom,
 	if ((ret = vmmci_restore(fd, vcp->vcp_id)) == -1)
 		return ret;
 
+	if ((ret = viombh_restore(fd, vcp)) == -1)
+		return ret;
+
 	return (0);
 }
 
@@ -2356,3 +2860,93 @@ virtio_dump(int fd)
 
 	return (0);
 }
+
+void
+virtio_stop(struct vm_create_params *vcp)
+{
+	uint8_t i;
+	for (i = 0; i < vcp->vcp_nnics; i++) {
+		if (event_del(&vionet[i].event)) {
+			log_warn("could not initialize vionet event "
+			    "handler");
+			return;
+		}
+	}
+}
+
+void
+virtio_start(struct vm_create_params *vcp)
+{
+	uint8_t i;
+	for (i = 0; i < vcp->vcp_nnics; i++) {
+		if (event_add(&vionet[i].event, NULL)) {
+			log_warn("could not initialize vionet event "
+			    "handler");
+			return;
+		}
+	}
+}
+
+void
+balloon_vm(struct vmd_vm *vm, uint32_t size)
+{
+	viombh.num_pages = size;
+
+	log_debug("%s: received request to balloon %d pages", __func__,
+	    size);
+
+	//if (viombh.num_pages > viombh.actual) {
+	viombh.cfg.isr_status |= VIRTIO_CONFIG_ISR_CONFIG_CHANGE;
+	vcpu_assert_pic_irq(viombh.vm_id, 0, viombh.irq);
+	//}
+}
+
+void
+stats_vm(struct vmd_vm *vm)
+{
+
+	uint64_t q_gpa;
+	uint32_t vr_sz;
+	uint16_t aidx, uidx;
+	char *buf;
+	struct vring_desc *desc;
+	struct vring_avail *avail;
+	struct vring_used *used;
+
+
+	vr_sz = vring_size(VIOMBH_QUEUE_SIZE);
+	q_gpa = viombh.vq[2].qa;
+	q_gpa = q_gpa * VIRTIO_PAGE_SIZE;
+
+	buf = calloc(1, vr_sz);
+	if (buf == NULL) {
+		log_warn("calloc error getting viombh ring");
+	}
+
+	if (read_mem(q_gpa, buf, vr_sz)) {
+		free(buf);
+		return;
+	}
+
+	desc = (struct vring_desc *)(buf);
+	avail = (struct vring_avail *)(buf +
+	    viombh.vq[2].vq_availoffset);
+	used = (struct vring_used *)(buf +
+	    viombh.vq[2].vq_usedoffset);
+
+	aidx = avail->idx & VIOMBH_QUEUE_MASK;
+	uidx = used->idx & VIOMBH_QUEUE_MASK;
+
+	viombh.cfg.isr_status = 1;
+	used->ring[uidx].id = avail->ring[aidx] & VIOMBH_QUEUE_MASK;
+	used->ring[uidx].len = desc[avail->ring[aidx]].len;
+	used->idx++;
+
+	if (write_mem(q_gpa, buf, vr_sz)) {
+		log_warnx("viombh: error writing vio ring");
+	}
+
+	vcpu_assert_pic_irq(viombh.vm_id, 0, viombh.irq);
+
+	free(buf);
+}
diff --git a/usr.sbin/vmd/vmm.c b/usr.sbin/vmd/vmm.c
index ab01e2589ce..375583bc672 100644
--- a/usr.sbin/vmd/vmm.c
+++ b/usr.sbin/vmd/vmm.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmm.c,v 1.93 2019/06/28 13:32:51 deraadt Exp $	*/
+/*	$OpenBSD: vmm.c,v 1.95 2019/12/11 06:45:17 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Mike Larkin <mlarkin@openbsd.org>
@@ -60,6 +60,7 @@ void vmm_run(struct privsep *, struct privsep_proc *, void *);
 void vmm_dispatch_vm(int, short, void *);
 int terminate_vm(struct vm_terminate_params *);
 int get_info_vm(struct privsep *, struct imsg *, int);
+int get_stats_vm(struct privsep *, struct imsg *, int);
 int opentap(char *);
 
 extern struct vmd *env;
@@ -109,6 +110,8 @@ vmm_dispatch_parent(int fd, struct privsep_proc *p, struct imsg *imsg)
 	struct vmop_id		 vid;
 	struct vmop_result	 vmr;
 	struct vmop_create_params vmc;
+	struct vmop_balloon_params vbp;
+	struct vmop_stats_params vsp;
 	uint32_t		 id = 0, peerid = imsg->hdr.peerid;
 	pid_t			 pid = 0;
 	unsigned int		 mode, flags;
@@ -198,7 +201,7 @@ vmm_dispatch_parent(int fd, struct privsep_proc *p, struct imsg *imsg)
 				/*
 				 * Request reboot but mark the VM as shutting
 				 * down. This way we can terminate the VM after
-				 * the triple fault instead of reboot and 
+				 * the triple fault instead of reboot and
 				 * avoid being stuck in the ACPI-less powerdown
 				 * ("press any key to reboot") of the VM.
 				 */
@@ -268,6 +271,34 @@ vmm_dispatch_parent(int fd, struct privsep_proc *p, struct imsg *imsg)
 			    -1, &verbose, sizeof(verbose));
 		}
 		break;
+	case IMSG_VMDOP_BALLOON_VM_REQUEST:
+		IMSG_SIZE_CHECK(imsg, &vbp);
+		memcpy(&vbp, imsg->data, sizeof(vbp));
+		id = vbp.vbp_id;
+		vm = vm_getbyvmid(id);
+		if ((vm = vm_getbyvmid(id)) == NULL) {
+			res = ENOENT;
+			cmd = IMSG_VMDOP_BALLOON_VM_RESPONSE;
+			break;
+		}
+		imsg_compose_event(&vm->vm_iev,
+		    imsg->hdr.type, imsg->hdr.peerid, imsg->hdr.pid,
+		    imsg->fd, &vbp, sizeof(vbp));
+		break;
+	case IMSG_VMDOP_STATS_VM_REQUEST:
+		IMSG_SIZE_CHECK(imsg, &vsp);
+		memcpy(&vsp, imsg->data, sizeof(vsp));
+		id = vsp.vsp_id;
+		vm = vm_getbyvmid(id);
+		if ((vm = vm_getbyvmid(id)) == NULL) {
+			res = ENOENT;
+			cmd = IMSG_VMDOP_STATS_VM_RESPONSE;
+			break;
+		}
+		imsg_compose_event(&vm->vm_iev,
+		    imsg->hdr.type, imsg->hdr.peerid, imsg->hdr.pid,
+		    imsg->fd, &vsp, sizeof(vsp));
+		break;
 	case IMSG_VMDOP_PAUSE_VM:
 		IMSG_SIZE_CHECK(imsg, &vid);
 		memcpy(&vid, imsg->data, sizeof(vid));
@@ -316,6 +347,7 @@ vmm_dispatch_parent(int fd, struct privsep_proc *p, struct imsg *imsg)
 		    imsg->hdr.peerid, vmc.vmc_owner.uid);
 		vm->vm_tty = imsg->fd;
 		vm->vm_state |= VM_STATE_RECEIVED;
+		vm->vm_state |= VM_STATE_PAUSED;
 		break;
 	case IMSG_VMDOP_RECEIVE_VM_END:
 		if ((vm = vm_getbyvmid(imsg->hdr.peerid)) == NULL) {
@@ -352,6 +384,16 @@ vmm_dispatch_parent(int fd, struct privsep_proc *p, struct imsg *imsg)
 	case IMSG_VMDOP_PAUSE_VM_RESPONSE:
 	case IMSG_VMDOP_UNPAUSE_VM_RESPONSE:
 	case IMSG_VMDOP_TERMINATE_VM_RESPONSE:
+	case IMSG_VMDOP_BALLOON_VM_RESPONSE:
+		memset(&vmr, 0, sizeof(vmr));
+		vmr.vmr_result = res;
+		vmr.vmr_id = id;
+		vmr.vmr_pid = pid;
+		if (proc_compose_imsg(ps, PROC_PARENT, -1, cmd,
+		    peerid, -1, &vmr, sizeof(vmr)) == -1)
+			return (-1);
+		break;
+	case IMSG_VMDOP_STATS_VM_RESPONSE:
 		memset(&vmr, 0, sizeof(vmr));
 		vmr.vmr_result = res;
 		vmr.vmr_id = id;
@@ -550,7 +592,24 @@ vmm_dispatch_vm(int fd, short event, void *arg)
 				}
 			}
 			break;
-
+		case IMSG_VMDOP_BALLOON_VM_RESPONSE:
+			for (i = 0; i < sizeof(procs); i++) {
+				if (procs[i].p_id == PROC_PARENT) {
+					proc_forward_imsg(procs[i].p_ps,
+					    &imsg, PROC_PARENT, -1);
+					break;
+				}
+			}
+			break;
+		case IMSG_VMDOP_STATS_VM_RESPONSE:
+			for (i = 0; i < sizeof(procs); i++) {
+				if (procs[i].p_id == PROC_PARENT) {
+					proc_forward_imsg(procs[i].p_ps,
+					    &imsg, PROC_PARENT, -1);
+					break;
+				}
+			}
+			break;
 		default:
 			fatalx("%s: got invalid imsg %d from %s",
 			    __func__, imsg.hdr.type,
@@ -590,7 +649,7 @@ terminate_vm(struct vm_terminate_params *vtp)
  * Opens the next available tap device, up to MAX_TAP.
  *
  * Parameters
- *  ifname: an optional buffer of at least IF_NAMESIZE bytes.
+ *  ifname: a buffer of at least IF_NAMESIZE bytes.
  *
  * Returns a file descriptor to the tap node opened, or -1 if no tap
  * devices were available.
@@ -601,16 +660,15 @@ opentap(char *ifname)
 	int i, fd;
 	char path[PATH_MAX];
 
-	strlcpy(ifname, "tap", IF_NAMESIZE);
 	for (i = 0; i < MAX_TAP; i++) {
 		snprintf(path, PATH_MAX, "/dev/tap%d", i);
 		fd = open(path, O_RDWR | O_NONBLOCK);
 		if (fd != -1) {
-			if (ifname != NULL)
-				snprintf(ifname, IF_NAMESIZE, "tap%d", i);
+			snprintf(ifname, IF_NAMESIZE, "tap%d", i);
 			return (fd);
 		}
 	}
+	strlcpy(ifname, "tap", IF_NAMESIZE);
 
 	return (-1);
 }
diff --git a/usr.sbin/vmd/vmd.c b/usr.sbin/vmd/vmd.c
index 9d329745a97..ad2d6663a7b 100644
--- a/usr.sbin/vmd/vmd.c
+++ b/usr.sbin/vmd/vmd.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmd.c,v 1.116 2019/09/04 07:02:03 mlarkin Exp $	*/
+/*	$OpenBSD: vmd.c,v 1.117 2019/12/12 03:53:38 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Reyk Floeter <reyk@openbsd.org>
@@ -21,6 +21,7 @@
 #include <sys/wait.h>
 #include <sys/cdefs.h>
 #include <sys/stat.h>
+#include <sys/sysctl.h>
 #include <sys/tty.h>
 #include <sys/ttycom.h>
 #include <sys/ioctl.h>
@@ -43,10 +44,12 @@
 
 #include <machine/specialreg.h>
 #include <machine/vmmvar.h>
+#include <pthread.h>
 
 #include "proc.h"
 #include "atomicio.h"
 #include "vmd.h"
+#include "virtio.h"
 
 __dead void usage(void);
 
@@ -63,6 +66,7 @@ int	 vm_instance(struct privsep *, struct vmd_vm **,
 	    struct vmop_create_params *, uid_t);
 int	 vm_checkinsflag(struct vmop_create_params *, unsigned int, uid_t);
 int	 vm_claimid(const char *, int, uint32_t *);
+void	 start_vm_batch(int, short, void*);
 
 struct vmd	*env;
 
@@ -73,6 +77,8 @@ static struct privsep_proc procs[] = {
 	{ "vmm",	PROC_VMM,	vmd_dispatch_vmm, vmm, vmm_shutdown },
 };
 
+struct event staggered_start_timer;
+
 /* For the privileged process */
 static struct privsep_proc *proc_priv = &procs[0];
 static struct passwd proc_privpw;
@@ -85,6 +91,8 @@ vmd_dispatch_control(int fd, struct privsep_proc *p, struct imsg *imsg)
 	int				 res = 0, ret = 0, cmd = 0, verbose;
 	unsigned int			 v = 0, flags;
 	struct vmop_create_params	 vmc;
+	struct vmop_balloon_params	 vbp;
+	struct vmop_stats_params	 vsp;
 	struct vmop_id			 vid;
 	struct vmop_result		 vmr;
 	struct vm_dump_header		 vmh;
@@ -94,6 +102,74 @@ vmd_dispatch_control(int fd, struct privsep_proc *p, struct imsg *imsg)
 	struct control_sock		*rcs;
 
 	switch (imsg->hdr.type) {
+	case IMSG_VMDOP_BALLOON_VM_REQUEST:
+		IMSG_SIZE_CHECK(imsg, &vbp);
+		memcpy(&vbp, imsg->data, sizeof(vbp));
+
+		if ((id = vbp.vbp_id) == 0) {
+			/* Lookup vm (id) by name */
+			if ((vm = vm_getbyname(vbp.vbp_name)) == NULL) {
+				res = ENOENT;
+				cmd = IMSG_VMDOP_BALLOON_VM_RESPONSE;
+				break;
+			} else if (!(vm->vm_state & VM_STATE_RUNNING)) {
+				res = EINVAL;
+				cmd = IMSG_VMDOP_BALLOON_VM_RESPONSE;
+				break;
+			}
+			id = vm->vm_vmid;
+		} else if ((vm = vm_getbyvmid(id)) == NULL) {
+			res = ENOENT;
+			cmd = IMSG_VMDOP_BALLOON_VM_RESPONSE;
+			break;
+		}
+		if (vm_checkperm(vm, &vm->vm_params.vmc_owner,
+		    vbp.vbp_uid) != 0) {
+			res = EPERM;
+			cmd = IMSG_VMDOP_BALLOON_VM_RESPONSE;
+			break;
+		}
+
+		vbp.vbp_id = id;
+
+		if (proc_compose_imsg(ps, PROC_VMM, -1, imsg->hdr.type,
+		    imsg->hdr.peerid, -1, &vbp, sizeof(vbp)) == -1)
+			return (-1);
+		break;
+	case IMSG_VMDOP_STATS_VM_REQUEST:
+		IMSG_SIZE_CHECK(imsg, &vsp);
+		memcpy(&vsp, imsg->data, sizeof(vsp));
+
+		if ((id = vsp.vsp_id) == 0) {
+			/* Lookup vm (id) by name */
+			if ((vm = vm_getbyname(vsp.vsp_name)) == NULL) {
+				res = ENOENT;
+				cmd = IMSG_VMDOP_STATS_VM_RESPONSE;
+				break;
+			} else if (!(vm->vm_state & VM_STATE_RUNNING)) {
+				res = EINVAL;
+				cmd = IMSG_VMDOP_STATS_VM_RESPONSE;
+				break;
+			}
+			id = vm->vm_vmid;
+		} else if ((vm = vm_getbyvmid(id)) == NULL) {
+			res = ENOENT;
+			cmd = IMSG_VMDOP_STATS_VM_RESPONSE;
+			break;
+		}
+		if (vm_checkperm(vm, &vm->vm_params.vmc_owner,
+		    vsp.vsp_uid) != 0) {
+			res = EPERM;
+			cmd = IMSG_VMDOP_STATS_VM_RESPONSE;
+			break;
+		}
+
+		vsp.vsp_id = id;
+
+		if (proc_compose_imsg(ps, PROC_VMM, -1, imsg->hdr.type,
+		    imsg->hdr.peerid, -1, &vsp, sizeof(vsp)) == -1)
+			return (-1);
+		break;
 	case IMSG_VMDOP_START_VM_REQUEST:
 		IMSG_SIZE_CHECK(imsg, &vmc);
 		memcpy(&vmc, imsg->data, sizeof(vmc));
@@ -333,6 +409,30 @@ vmd_dispatch_vmm(int fd, struct privsep_proc *p, struct imsg *imsg)
 	struct vmop_info_result	 vir;
 
 	switch (imsg->hdr.type) {
+	case IMSG_VMDOP_BALLOON_VM_RESPONSE:
+		IMSG_SIZE_CHECK(imsg, &vmr);
+		memcpy(&vmr, imsg->data, sizeof(vmr));
+		if ((vm = vm_getbyvmid(vmr.vmr_id)) == NULL)
+			break;
+		proc_compose_imsg(ps, PROC_CONTROL, -1,
+		    imsg->hdr.type, imsg->hdr.peerid, -1,
+		    imsg->data, sizeof(imsg->data));
+		log_info("%s: ballooned vm %d successfully",
+		    vm->vm_params.vmc_params.vcp_name,
+		    vm->vm_vmid);
+		break;
+	case IMSG_VMDOP_STATS_VM_RESPONSE:
+		IMSG_SIZE_CHECK(imsg, &vmr);
+		memcpy(&vmr, imsg->data, sizeof(vmr));
+		if ((vm = vm_getbyvmid(vmr.vmr_id)) == NULL)
+			break;
+		proc_compose_imsg(ps, PROC_CONTROL, -1,
+		    imsg->hdr.type, imsg->hdr.peerid, -1,
+		    imsg->data, sizeof(imsg->data));
+		log_info("%s: stats of vm %d updated successfully",
+		    vm->vm_params.vmc_params.vcp_name,
+		    vm->vm_vmid);
+		break;
 	case IMSG_VMDOP_PAUSE_VM_RESPONSE:
 		IMSG_SIZE_CHECK(imsg, &vmr);
 		memcpy(&vmr, imsg->data, sizeof(vmr));
@@ -854,11 +954,40 @@ main(int argc, char **argv)
 	return (0);
 }
 
+void
+start_vm_batch(int fd, short type, void *args)
+{
+	int		i = 0;
+	struct vmd_vm	*vm;
+
+	log_debug("%s: starting batch of %d vms", __func__,
+	    env->vmd_cfg.parallelism);
+	TAILQ_FOREACH(vm, env->vmd_vms, vm_entry) {
+		if (!(vm->vm_state & VM_STATE_WAITING)) {
+			log_debug("%s: not starting vm %s (disabled)",
+			    __func__,
+			    vm->vm_params.vmc_params.vcp_name);
+			continue;
+		}
+		i++;
+		if (i > env->vmd_cfg.parallelism) {
+			evtimer_add(&staggered_start_timer,
+			    &env->vmd_cfg.delay);
+			break;
+		}
+		vm->vm_state &= ~VM_STATE_WAITING;
+		config_setvm(&env->vmd_ps, vm, -1, vm->vm_params.vmc_owner.uid);
+	}
+	log_debug("%s: done starting vms", __func__);
+}
+
 int
 vmd_configure(void)
 {
-	struct vmd_vm		*vm;
+	int			ncpus;
 	struct vmd_switch	*vsw;
+	int ncpu_mib[] = {CTL_HW, HW_NCPUONLINE};
+	size_t ncpus_sz = sizeof(ncpus);
 
 	if ((env->vmd_ptmfd = open(PATH_PTMDEV, O_RDWR|O_CLOEXEC)) == -1)
 		fatal("open %s", PATH_PTMDEV);
@@ -906,18 +1035,21 @@ vmd_configure(void)
 		}
 	}
 
-	TAILQ_FOREACH(vm, env->vmd_vms, vm_entry) {
-		if (vm->vm_state & VM_STATE_DISABLED) {
-			log_debug("%s: not creating vm %s (disabled)",
-			    __func__,
-			    vm->vm_params.vmc_params.vcp_name);
-			continue;
-		}
-		if (config_setvm(&env->vmd_ps, vm,
-		    -1, vm->vm_params.vmc_owner.uid) == -1)
-			return (-1);
+	if (!(env->vmd_cfg.cfg_flags & VMD_CFG_STAGGERED_START)) {
+		env->vmd_cfg.delay.tv_sec = VMD_DEFAULT_STAGGERED_START_DELAY;
+		if (sysctl(ncpu_mib, NELEM(ncpu_mib), &ncpus, &ncpus_sz, NULL, 0) == -1)
+			ncpus = 1;
+		env->vmd_cfg.parallelism = ncpus;
+		log_debug("%s: setting staggered start configuration to "
+		    "parallelism: %d and delay: %lld",
+		    __func__, ncpus, (long long) env->vmd_cfg.delay.tv_sec);
 	}
 
+	log_debug("%s: starting vms in staggered fashion", __func__);
+	evtimer_set(&staggered_start_timer, start_vm_batch, NULL);
+	/* start first batch */
+	start_vm_batch(0, 0, NULL);
+
 	return (0);
 }
 
@@ -983,24 +1115,12 @@ vmd_reload(unsigned int reset, const char *filename)
 			}
 		}
 
-		TAILQ_FOREACH(vm, env->vmd_vms, vm_entry) {
-			if (!(vm->vm_state & VM_STATE_RUNNING)) {
-				if (vm->vm_state & VM_STATE_DISABLED) {
-					log_debug("%s: not creating vm %s"
-					    " (disabled)", __func__,
-					    vm->vm_params.vmc_params.vcp_name);
-					continue;
-				}
-				if (config_setvm(&env->vmd_ps, vm,
-				    -1, vm->vm_params.vmc_owner.uid) == -1)
-					return (-1);
-			} else {
-				log_debug("%s: not creating vm \"%s\": "
-				    "(running)", __func__,
-				    vm->vm_params.vmc_params.vcp_name);
-			}
+		log_debug("%s: starting vms in staggered fashion", __func__);
+		evtimer_set(&staggered_start_timer, start_vm_batch, NULL);
+		/* start first batch */
+		start_vm_batch(0, 0, NULL);
+
 		}
-	}
 
 	return (0);
 }
@@ -1021,6 +1141,7 @@ vmd_shutdown(void)
 
 	log_warnx("parent terminating");
 	exit(0);
+
 }
 
 struct vmd_vm *
diff --git a/usr.sbin/vmd/vmd.h b/usr.sbin/vmd/vmd.h
index f6368dc621d..282a772b30d 100644
--- a/usr.sbin/vmd/vmd.h
+++ b/usr.sbin/vmd/vmd.h
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmd.h,v 1.97 2019/09/07 09:11:14 tobhe Exp $	*/
+/*	$OpenBSD: vmd.h,v 1.98 2019/12/12 03:53:38 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Mike Larkin <mlarkin@openbsd.org>
@@ -39,6 +39,7 @@
 #define SET(_v, _m)		((_v) |= (_m))
 #define CLR(_v, _m)		((_v) &= ~(_m))
 #define ISSET(_v, _m)		((_v) & (_m))
+#define NELEM(a) (sizeof(a) / sizeof((a)[0]))
 
 #define VMD_USER		"_vmd"
 #define VMD_CONF		"/etc/vm.conf"
@@ -56,6 +57,8 @@
 #define VMD_SWITCH_TYPE		"bridge"
 #define VM_DEFAULT_MEMORY	512
 
+#define VMD_DEFAULT_STAGGERED_START_DELAY 30
+
 /* Rate-limit fast reboots */
 #define VM_START_RATE_SEC	6	/* min. seconds since last reboot */
 #define VM_START_RATE_LIMIT	3	/* max. number of fast reboots */
@@ -120,6 +123,10 @@ enum imsg_type {
 	IMSG_VMDOP_VM_SHUTDOWN,
 	IMSG_VMDOP_VM_REBOOT,
 	IMSG_VMDOP_CONFIG,
+	IMSG_VMDOP_BALLOON_VM_REQUEST,
+	IMSG_VMDOP_BALLOON_VM_RESPONSE,
+	IMSG_VMDOP_STATS_VM_REQUEST,
+	IMSG_VMDOP_STATS_VM_RESPONSE,
 	IMSG_VMDOP_DONE
 };
 
@@ -160,6 +167,19 @@ struct vmop_owner {
 	int64_t			 gid;
 };
 
+struct vmop_balloon_params {
+	uid_t			vbp_uid;
+	uint32_t		vbp_id;
+	char			vbp_name[VMM_MAX_NAME_LEN];
+	uint32_t		vbp_memsize;
+};
+
+struct vmop_stats_params {
+	uid_t			vsp_uid;
+	uint32_t		vsp_id;
+	char			vsp_name[VMM_MAX_NAME_LEN];
+};
+
 struct vmop_create_params {
 	struct vm_create_params	 vmc_params;
 	unsigned int		 vmc_flags;
@@ -280,6 +300,7 @@ struct vmd_vm {
 #define VM_STATE_SHUTDOWN	0x04
 #define VM_STATE_RECEIVED	0x08
 #define VM_STATE_PAUSED		0x10
+#define VM_STATE_WAITING	0x20
 
 	/* For rate-limiting */
 	struct timeval		 vm_start_tv;
@@ -319,7 +340,10 @@ struct vmd_config {
 	unsigned int		 cfg_flags;
 #define VMD_CFG_INET6		0x01
 #define VMD_CFG_AUTOINET6	0x02
+#define VMD_CFG_STAGGERED_START	0x04
 
+	struct timeval		 delay;
+	int			 parallelism;
 	struct address		 cfg_localprefix;
 	struct address		 cfg_localprefix6;
 };
@@ -345,6 +369,10 @@ struct vmd {
 	int			 vmd_fd;
 	int			 vmd_fd6;
 	int			 vmd_ptmfd;
+	 /* Memory balloon settings from vm.conf */
+	int			 vmb_lowat;
+    int          vmb_hiwat;
+    int          vmb_reclaim;
 };
 
 static inline struct sockaddr_in *
@@ -405,6 +433,7 @@ char	*get_string(uint8_t *, size_t);
 uint32_t prefixlen2mask(uint8_t);
 void	 prefixlen2mask6(u_int8_t, struct in6_addr *);
 void	 getmonotime(struct timeval *);
+void	 *vm_pthread_fxn(void *p);
 
 /* priv.c */
 void	 priv(struct privsep *, struct privsep_proc *);
diff --git a/usr.sbin/vmd/vm.c b/usr.sbin/vmd/vm.c
index 48776a74971..63c17aad0e9 100644
--- a/usr.sbin/vmd/vm.c
+++ b/usr.sbin/vmd/vm.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vm.c,v 1.51 2019/07/17 05:51:07 pd Exp $	*/
+/*	$OpenBSD: vm.c,v 1.56 2020/04/21 03:36:56 pd Exp $	*/
 
 /*
  * Copyright (c) 2015 Mike Larkin <mlarkin@openbsd.org>
@@ -81,6 +81,7 @@ void init_emulated_hw(struct vmop_create_params *, int,
 void restore_emulated_hw(struct vm_create_params *, int, int *,
     int[][VM_MAX_BASE_PER_DISK],int);
 void vcpu_exit_inout(struct vm_run_params *);
+int vcpu_exit_eptviolation(struct vm_run_params *);
 uint8_t vcpu_exit_pci(struct vm_run_params *);
 int vcpu_pic_intr(uint32_t, uint32_t, uint8_t);
 int loadfile_bios(FILE *, struct vcpu_reg_state *);
@@ -111,6 +112,9 @@ pthread_cond_t threadcond;
 
 pthread_cond_t vcpu_run_cond[VMM_MAX_VCPUS_PER_VM];
 pthread_mutex_t vcpu_run_mtx[VMM_MAX_VCPUS_PER_VM];
+pthread_barrier_t vm_pause_barrier;
+pthread_cond_t vcpu_unpause_cond[VMM_MAX_VCPUS_PER_VM];
+pthread_mutex_t vcpu_unpause_mtx[VMM_MAX_VCPUS_PER_VM];
 uint8_t vcpu_hlt[VMM_MAX_VCPUS_PER_VM];
 uint8_t vcpu_done[VMM_MAX_VCPUS_PER_VM];
 
@@ -365,10 +369,10 @@ start_vm(struct vmd_vm *vm, int fd)
 	if (vm->vm_state & VM_STATE_RECEIVED) {
 		restore_emulated_hw(vcp, vm->vm_receive_fd, nicfds,
 		    vm->vm_disks, vm->vm_cdrom);
-		mc146818_start();
 		restore_mem(vm->vm_receive_fd, vcp);
 		if (restore_vm_params(vm->vm_receive_fd, vcp))
 			fatal("restore vm params failed");
+		unpause_vm(vcp);
 	}
 
 	if (vmm_pipe(vm, fd, vm_dispatch_vmm) == -1)
@@ -398,6 +402,8 @@ vm_dispatch_vmm(int fd, short event, void *arg)
 	struct imsg		 imsg;
 	ssize_t			 n;
 	int			 verbose;
+	struct vmop_balloon_params vbp;
+	struct vmop_stats_params vsp;
 
 	if (event & EV_READ) {
 		if ((n = imsg_read(ibuf)) == -1 && errno != EAGAIN)
@@ -439,6 +445,26 @@ vm_dispatch_vmm(int fd, short event, void *arg)
 			if (vmmci_ctl(VMMCI_REBOOT) == -1)
 				_exit(0);
 			break;
+		case IMSG_VMDOP_BALLOON_VM_REQUEST:
+			memcpy(&vbp, imsg.data, sizeof(vbp));
+			vmr.vmr_result = 0;
+			vmr.vmr_id = vm->vm_vmid;
+			balloon_vm(vm, vbp.vbp_memsize / PAGE_SIZE);
+			imsg_compose_event(&vm->vm_iev,
+			    IMSG_VMDOP_BALLOON_VM_RESPONSE,
+			    imsg.hdr.peerid, imsg.hdr.pid, -1, &vmr,
+			    sizeof(vmr));
+			break;
+		case IMSG_VMDOP_STATS_VM_REQUEST:
+			memcpy(&vsp, imsg.data, sizeof(vsp));
+			vmr.vmr_result = 0;
+			vmr.vmr_id = vm->vm_vmid;
+			stats_vm(vm);
+			imsg_compose_event(&vm->vm_iev,
+			    IMSG_VMDOP_STATS_VM_RESPONSE,
+			    imsg.hdr.peerid, imsg.hdr.pid, -1, &vmr,
+			    sizeof(vmr));
+			break;
 		case IMSG_VMDOP_PAUSE_VM:
 			vmr.vmr_result = 0;
 			vmr.vmr_id = vm->vm_vmid;
diff --git a/sys/dev/pv/viomb.c b/sys/dev/pv/viomb.c
index 8e486476a6c..c1c81e9fb89 100644
--- a/sys/dev/pv/viomb.c
+++ b/sys/dev/pv/viomb.c
@@ -26,7 +26,7 @@
  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
-
+#include <sys/syslog.h>
 #include <sys/param.h>
 #include <sys/systm.h>
 #include <sys/malloc.h>
@@ -36,9 +36,17 @@
 #include <sys/sensors.h>
 
 #include <uvm/uvm_extern.h>
+#include <uvm/uvmexp.h>
+#include <sys/sysctl.h>
+#include <sys/mount.h>
 
 #include <dev/pv/virtioreg.h>
 #include <dev/pv/virtiovar.h>
+#include <dev/pci/virtio_pcireg.h>
+
+
+extern struct uvmexp uvmexp;
+extern struct bcachestats bcstats;
 
 #if VIRTIO_PAGE_SIZE!=PAGE_SIZE
 #error non-4K page sizes are not supported yet
@@ -68,20 +76,37 @@
 #define VIRTIO_BALLOON_CONFIG_ACTUAL	4	/* 32bit */
 
 /* Feature bits */
-#define VIRTIO_BALLOON_F_MUST_TELL_HOST (1ULL<<0)
-#define VIRTIO_BALLOON_F_STATS_VQ	(1ULL<<1)
+#define VIRTIO_BALLOON_F_MUST_TELL_HOST 0
+#define VIRTIO_BALLOON_F_STATS_VQ		1
+
+#define VIOMB_STATS_MAX		  6   /* Maximum number of tags */
+#define VIRTIO_BALLOON_S_SWAP_IN  0   /* Amount of memory swapped in */
+#define VIRTIO_BALLOON_S_SWAP_OUT 1   /* Amount of memory swapped out */
+#define VIRTIO_BALLOON_S_MAJFLT   2   /* Number of major faults */
+#define VIRTIO_BALLOON_S_MINFLT   3   /* Number of minor faults (N/A) */
+#define VIRTIO_BALLOON_S_MEMFREE  4   /* Total amount of free memory */
+#define VIRTIO_BALLOON_S_MEMTOT   5   /* Total amount of memory */
+#define VIRTIO_BALLOON_S_AVAIL    6   /* How much mem is free w/o swapping */
+#define VIRTIO_BALLOON_S_CACHES   7   /* Current amout of mem in page cache */
+#define VIRTIO_BALLOON_S_HTML_PGALLOC 8 /* HugeTLB page allocations (N/A) */
+#define VIRTIO_BALLOON_S_HTML_PGFAIL  9 /* HugeTLB page failures (N/A) */
+
+#define VIOMB_BUFSIZE 16
 
 static const struct virtio_feature_name viomb_feature_names[] = {
-#if VIRTIO_DEBUG
 	{VIRTIO_BALLOON_F_MUST_TELL_HOST, "TellHost"},
 	{VIRTIO_BALLOON_F_STATS_VQ, "StatVQ"},
-#endif
 	{0, NULL}
 };
-#define PGS_PER_REQ		256	/* 1MB, 4KB/page */
+#define PGS_PER_REQ	256	/* 1MB, 4KB/page */
 #define VQ_INFLATE	0
 #define VQ_DEFLATE	1
+#define VQ_STATS	2
 
+/*
+ * This struct will be viewed by host and driver
+ *
+ */
 struct balloon_req {
 	bus_dmamap_t	 bl_dmamap;
 	struct pglist	 bl_pglist;
@@ -89,30 +114,54 @@ struct balloon_req {
 	u_int32_t	*bl_pages;
 };
 
+struct virtio_balloon_stat {
+	uint16_t tag;
+	uint64_t val;
+} __attribute__((packed));
+
+/*
+ * Holds the global state of the viomb driver
+ * Just for driver
+ */
 struct viomb_softc {
-	struct device		sc_dev;
-	struct virtio_softc	*sc_virtio;
-	struct virtqueue	sc_vq[2];
-	u_int32_t		sc_npages; /* desired pages */
-	u_int32_t		sc_actual; /* current pages */
-	struct balloon_req	sc_req;
-	struct taskq		*sc_taskq;
-	struct task		sc_task;
-	struct pglist		sc_balloon_pages;
-	struct ksensor		sc_sens[2];
-	struct ksensordev	sc_sensdev;
+	struct device			sc_dev;
+	struct virtio_softc		*sc_virtio;
+	struct virtqueue		sc_vq[3];
+	u_int32_t			sc_npages;
+	u_int32_t			sc_actual;
+	struct balloon_req		sc_req;
+	struct taskq			*sc_taskq;
+	struct taskq			*sc_stats_taskq;
+	struct task			sc_task;
+	struct task			sc_stats_task;
+	struct pglist			sc_balloon_pages;
+	struct ksensor			sc_sens[2];
+	struct ksensordev		sc_sensdev;
+	bus_dmamap_t        		sc_stats_dmamap;
+	struct virtio_balloon_stat 	*sc_stats_buf;
 };
 
 int	viomb_match(struct device *, void *, void *);
 void	viomb_attach(struct device *, struct device *, void *);
 void	viomb_worker(void *);
+void	viomb_stats_worker(void *);
 void	viomb_inflate(struct viomb_softc *);
 void	viomb_deflate(struct viomb_softc *);
+
+void    viomb_stats(struct viomb_softc *);
+
 int	viomb_config_change(struct virtio_softc *);
 void	viomb_read_config(struct viomb_softc *);
 int	viomb_vq_dequeue(struct virtqueue *);
+int	viomb_vq_dequeue(struct virtqueue *);
 int	viomb_inflate_intr(struct virtqueue *);
 int	viomb_deflate_intr(struct virtqueue *);
+int	viomb_stats_intr(struct virtqueue *);
+
+int	viomb_stats_intr(struct virtqueue *);
+void	get_memory_stats(struct viomb_softc *);
+
+int viomb_stats_done_first;
 
 struct cfattach viomb_ca = {
 	sizeof(struct viomb_softc), viomb_match, viomb_attach
@@ -134,6 +183,7 @@ viomb_match(struct device *parent, void *match, void *aux)
 void
 viomb_attach(struct device *parent, struct device *self, void *aux)
 {
+	printf("%s - attaching viomb \n",__func__);
 	struct viomb_softc *sc = (struct viomb_softc *)self;
 	struct virtio_softc *vsc = (struct virtio_softc *)parent;
 	int i;
@@ -151,6 +201,7 @@ viomb_attach(struct device *parent, struct device *self, void *aux)
 		return;
 	}
 
+	// vsc is global
 	sc->sc_virtio = vsc;
 	vsc->sc_vqs = &sc->sc_vq[VQ_INFLATE];
 	vsc->sc_nvqs = 0;
@@ -158,7 +209,8 @@ viomb_attach(struct device *parent, struct device *self, void *aux)
 	vsc->sc_ipl = IPL_BIO;
 	vsc->sc_config_change = viomb_config_change;
 
-	vsc->sc_driver_features = VIRTIO_BALLOON_F_MUST_TELL_HOST;
+	vsc->sc_driver_features = VIRTIO_BALLOON_F_MUST_TELL_HOST |
+	    VIRTIO_BALLOON_F_STATS_VQ;
 	if (virtio_negotiate_features(vsc, viomb_feature_names) != 0)
 		goto err;
 
@@ -170,11 +222,17 @@ viomb_attach(struct device *parent, struct device *self, void *aux)
 	     sizeof(u_int32_t) * PGS_PER_REQ, 1, "deflate") != 0))
 		goto err;
 	vsc->sc_nvqs++;
+	if ((virtio_alloc_vq(vsc, &sc->sc_vq[VQ_STATS], VQ_STATS,
+	     VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat), 1, "stats") != 0))
+		goto err;
+	vsc->sc_nvqs++;
 
 	sc->sc_vq[VQ_INFLATE].vq_done = viomb_inflate_intr;
 	sc->sc_vq[VQ_DEFLATE].vq_done = viomb_deflate_intr;
+	sc->sc_vq[VQ_STATS].vq_done = viomb_stats_intr;
 	virtio_start_vq_intr(vsc, &sc->sc_vq[VQ_INFLATE]);
 	virtio_start_vq_intr(vsc, &sc->sc_vq[VQ_DEFLATE]);
+	virtio_start_vq_intr(vsc, &sc->sc_vq[VQ_STATS]);
 
 	viomb_read_config(sc);
 	TAILQ_INIT(&sc->sc_balloon_pages);
@@ -198,11 +256,37 @@ viomb_attach(struct device *parent, struct device *self, void *aux)
 		goto err_dmamap;
 	}
 
+	if ((sc->sc_stats_buf = dma_alloc(VIOMB_STATS_MAX *
+	    sizeof(struct virtio_balloon_stat), PR_NOWAIT|PR_ZERO)) == NULL) {
+		printf("%s: Can't alloc DMA memory.\n", DEVNAME(sc));
+		goto err_dmamap;
+	}
+	if (bus_dmamap_create(vsc->sc_dmat,
+	    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+	    1, VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat), 0,
+	    BUS_DMA_NOWAIT, &sc->sc_stats_dmamap)) {
+		printf("%s: dmamap creation failed.\n", DEVNAME(sc));
+		goto err_dmamap;
+	}
+	if (bus_dmamap_load(vsc->sc_dmat, sc->sc_stats_dmamap,
+	    sc->sc_stats_buf,
+	    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+	    NULL, BUS_DMA_NOWAIT)) {
+		printf("%s: dmamap load failed.\n", DEVNAME(sc));
+		goto err_dmamap2;
+	}
+
 	sc->sc_taskq = taskq_create("viomb", 1, IPL_BIO, 0);
 	if (sc->sc_taskq == NULL)
-		goto err_dmamap;
+		goto err_dmamap2;
 	task_set(&sc->sc_task, viomb_worker, sc);
 
+	sc->sc_stats_taskq = taskq_create("viomb_stats", 1, IPL_BIO, 0);
+	if (sc->sc_stats_taskq == NULL)
+		goto err_dmamap2;
+	task_set(&sc->sc_stats_task, viomb_stats_worker, sc);
+	task_add(sc->sc_stats_taskq, &sc->sc_stats_task);
+
 	strlcpy(sc->sc_sensdev.xname, DEVNAME(sc),
 	    sizeof(sc->sc_sensdev.xname));
 	strlcpy(sc->sc_sens[0].desc, "desired",
@@ -221,15 +305,22 @@ viomb_attach(struct device *parent, struct device *self, void *aux)
 
 	printf("\n");
 	return;
+
+err_dmamap2:
+	bus_dmamap_destroy(vsc->sc_dmat, sc->sc_stats_dmamap);
 err_dmamap:
 	bus_dmamap_destroy(vsc->sc_dmat, sc->sc_req.bl_dmamap);
 err:
 	if (sc->sc_req.bl_pages)
 		dma_free(sc->sc_req.bl_pages, sizeof(u_int32_t) * PGS_PER_REQ);
+	if (sc->sc_stats_buf)
+		dma_free(sc->sc_stats_buf,
+		    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat));
 	for (i = 0; i < vsc->sc_nvqs; i++)
 		virtio_free_vq(vsc, &sc->sc_vq[i]);
 	vsc->sc_nvqs = 0;
 	vsc->sc_child = VIRTIO_CHILD_ERROR;
+
 	return;
 }
 
@@ -255,13 +346,13 @@ viomb_worker(void *arg1)
 	s = splbio();
 	viomb_read_config(sc);
 	if (sc->sc_npages > sc->sc_actual){
-		VIOMBDEBUG(sc, "inflating balloon from %u to %u.\n",
-			   sc->sc_actual, sc->sc_npages);
+		printf("%s: inflating balloon from %u to %u.\n", __func__,
+		   sc->sc_actual, sc->sc_npages);
 		viomb_inflate(sc);
 		}
 	else if (sc->sc_npages < sc->sc_actual){
-		VIOMBDEBUG(sc, "deflating balloon from %u to %u.\n",
-			   sc->sc_actual, sc->sc_npages);
+		printf("%s: deflating balloon from %u to %u.\n", __func__,
+		   sc->sc_actual, sc->sc_npages);
 		viomb_deflate(sc);
 	}
 
@@ -271,6 +362,33 @@ viomb_worker(void *arg1)
 	splx(s);
 }
 
+void
+viomb_stats_worker(void *arg1)
+{
+	struct viomb_softc *sc = (struct viomb_softc *)arg1;
+
+	int s, i;
+
+	s = splbio();
+	printf("%s: entered\n", __func__);
+	printf("%s: getting memory statistics\n", __func__);
+	viomb_stats(sc);
+	for (i = 0; i < VIOMB_STATS_MAX; i++)
+		printf("%s: stats[%d]: tag=0x%x val=0x%llx\n", __func__, i,
+		    sc->sc_stats_buf[i].tag,
+		    sc->sc_stats_buf[i].val);
+
+	printf("%s: leaving\n", __func__);
+	splx(s);
+
+}
+
+/*
+ *
+  * viomb_softc defined in viomb.c
+  *
+  * Parameter: sc is a global reference to the viomb driver state
+  */
 void
 viomb_inflate(struct viomb_softc *sc)
 {
@@ -279,15 +397,26 @@ viomb_inflate(struct viomb_softc *sc)
 	struct vm_page *p;
 	struct virtqueue *vq = &sc->sc_vq[VQ_INFLATE];
 	u_int32_t nvpages;
-	int slot, error, i = 0;
+	int slot, error, i = 0, j = 0;
 
 	nvpages = sc->sc_npages - sc->sc_actual;
 	if (nvpages > PGS_PER_REQ)
 		nvpages = PGS_PER_REQ;
 	b = &sc->sc_req;
 
+	TAILQ_INIT(&b->bl_pglist);
+
+	printf("%d: bl_pglist is empty\n", TAILQ_EMPTY(&b->bl_pglist));
+
+	/*  API call for allocating pages
+	 *
+	 *  - creates bl_pglist of size nvpages
+	 *  - allocates memory for the entire bl_pglist
+	 *  - bl_pglist will be the list of free pages to give to host
+	 */
 	if ((error = uvm_pglistalloc(nvpages * PAGE_SIZE, 0,
-				     dma_constraint.ucr_high,
+				     //dma_constraint.ucr_high,
+					 -1, //or uint64_t or 500 megs
 				     0, 0, &b->bl_pglist, nvpages,
 				     UVM_PLA_NOWAIT))) {
 		printf("%s unable to allocate %u physmem pages,"
@@ -296,6 +425,10 @@ viomb_inflate(struct viomb_softc *sc)
 	}
 
 	b->bl_nentries = nvpages;
+
+	TAILQ_FOREACH(p, &b->bl_pglist, pageq)
+		printf("%s: page %d # 0x%llx \n", __func__, j++, (uint64_t)p->phys_addr);
+
 	TAILQ_FOREACH(p, &b->bl_pglist, pageq)
 		b->bl_pages[i++] = p->phys_addr / VIRTIO_PAGE_SIZE;
 
@@ -311,14 +444,22 @@ viomb_inflate(struct viomb_softc *sc)
 		       DEVNAME(sc), vq->vq_num);
 		goto err;
 	}
+
 	bus_dmamap_sync(vsc->sc_dmat, b->bl_dmamap, 0,
 			sizeof(u_int32_t) * nvpages, BUS_DMASYNC_PREWRITE);
 	virtio_enqueue_p(vq, slot, b->bl_dmamap, 0,
 			 sizeof(u_int32_t) * nvpages, VRING_READ);
+
+	//sc->sc_actual = sc->sc_actual + nvpages;
+	printf("virtio_write_device_config_4 updating actual: %d \n", sc->sc_actual);
+	// virtio_write_device_config_4(vsc, VIRTIO_BALLOON_CONFIG_ACTUAL,
+	// 	sc->sc_actual);
+
 	virtio_enqueue_commit(vsc, vq, slot, VRING_NOTIFY);
 	return;
 err:
 	uvm_pglistfree(&b->bl_pglist);
+	printf("%s, err: vq->vq_num: %u \n", __func__, vq->vq_num);
 	return;
 }
 
@@ -361,13 +502,13 @@ viomb_deflate(struct viomb_softc *sc)
 		goto err;
 	}
 	bus_dmamap_sync(vsc->sc_dmat, b->bl_dmamap, 0,
-		    sizeof(u_int32_t) * nvpages,
-		    BUS_DMASYNC_PREWRITE);
+	    sizeof(u_int32_t) * nvpages, BUS_DMASYNC_PREWRITE);
 	virtio_enqueue_p(vq, slot, b->bl_dmamap, 0,
-			 sizeof(u_int32_t) * nvpages, VRING_READ);
+	    sizeof(u_int32_t) * nvpages, VRING_READ);
 
 	if (!virtio_has_feature(vsc, VIRTIO_BALLOON_F_MUST_TELL_HOST))
 		uvm_pglistfree(&b->bl_pglist);
+
 	virtio_enqueue_commit(vsc, vq, slot, VRING_NOTIFY);
 	return;
 err:
@@ -378,6 +519,58 @@ err:
 	return;
 }
 
+void
+viomb_stats(struct viomb_softc *sc)
+{
+	struct virtio_softc *vsc = (struct virtio_softc *)sc->sc_virtio;
+	struct virtqueue *vq = &sc->sc_vq[VQ_STATS];
+	int slot;
+
+	printf("%s: entered\n", __func__);
+
+	if ((virtio_enqueue_prep(vq, &slot)) > 0) {
+		printf("%s:virtio_enqueue_prep() vq_num %d\n",
+		       DEVNAME(sc), vq->vq_num);
+		return;
+	}
+
+	if (virtio_enqueue_reserve(vq, slot, 1)) {
+		printf("%s:virtio_enqueue_reserve vq_num %d\n",
+		       DEVNAME(sc), vq->vq_num);
+		return;
+	}
+
+	printf("%s: got slot=%d\n", __func__, slot);
+
+	if (viomb_stats_done_first) {
+		get_memory_stats(sc);
+		bus_dmamap_sync(vsc->sc_dmat, sc->sc_stats_dmamap, 0,
+		    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+		    BUS_DMASYNC_PREWRITE);
+
+		virtio_enqueue_p(vq, slot,  sc->sc_stats_dmamap, 0,
+		    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+		    VRING_WRITE);
+	} else {
+		viomb_stats_done_first = 1;
+		printf("%s: empty buf (first time)\n", __func__);
+		memset(sc->sc_stats_buf, 0,
+		    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat));
+
+		bus_dmamap_sync(vsc->sc_dmat, sc->sc_stats_dmamap, 0,
+		    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+		    BUS_DMASYNC_PREWRITE);
+
+		virtio_enqueue_p(vq, slot,  sc->sc_stats_dmamap, 0,
+		    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+		    VRING_WRITE);
+	}
+
+	virtio_enqueue_commit(vsc, vq, slot, VRING_NOTIFY);
+
+	printf("%s: leaving\n", __func__);
+}
+
 void
 viomb_read_config(struct viomb_softc *sc)
 {
@@ -409,9 +602,6 @@ viomb_vq_dequeue(struct virtqueue *vq)
 	return(0);
 }
 
-/*
- * interrupt handling for vq's
- */
 int
 viomb_inflate_intr(struct virtqueue *vq)
 {
@@ -433,11 +623,13 @@ viomb_inflate_intr(struct virtqueue *vq)
 		p = TAILQ_FIRST(&b->bl_pglist);
 		TAILQ_REMOVE(&b->bl_pglist, p, pageq);
 		TAILQ_INSERT_TAIL(&sc->sc_balloon_pages, p, pageq);
-	}
+ 	}
 	VIOMBDEBUG(sc, "updating sc->sc_actual from %u to %llu\n",
 		   sc->sc_actual, sc->sc_actual + nvpages);
+
 	virtio_write_device_config_4(vsc, VIRTIO_BALLOON_CONFIG_ACTUAL,
 				     sc->sc_actual + nvpages);
+
 	viomb_read_config(sc);
 
 	/* if we have more work to do, add it to the task list */
@@ -479,3 +671,69 @@ viomb_deflate_intr(struct virtqueue *vq)
 
 	return(1);
 }
+
+/*
+ * viomb_stats_intr
+ *
+ * Interrupt handler for when device wants memory statistics from driver
+ */
+int
+viomb_stats_intr(struct virtqueue *vq)
+{
+	struct virtio_softc *vsc = vq->vq_owner;
+	struct viomb_softc *sc = (struct viomb_softc *)vsc->sc_child;
+
+	if (viomb_vq_dequeue(vq))
+		return(1);
+
+	bus_dmamap_sync(vsc->sc_dmat, sc->sc_stats_dmamap, 0,
+	    VIOMB_STATS_MAX * sizeof(struct virtio_balloon_stat),
+	    BUS_DMASYNC_POSTWRITE);
+
+	if (virtio_has_feature(vsc, VIRTIO_BALLOON_F_STATS_VQ))
+		task_add(sc->sc_stats_taskq, &sc->sc_stats_task);
+
+	return(1);
+}
+
+/*
+ * get_memory_stats
+ *
+ * The host/VMM has requested new stats to be sent. Gather these from
+ * UVM and other places and update our local array of tags/values in
+ * the softc.
+ *
+ * Parameters:
+ *  sc: Our softc
+ */
+void
+get_memory_stats(struct viomb_softc *sc)
+{
+	struct virtio_balloon_stat *s;
+
+	s = (struct virtio_balloon_stat *)sc->sc_stats_buf;
+
+	s[0].tag = VIRTIO_BALLOON_S_SWAP_IN;
+	s[0].val = uvmexp.swpginuse * PAGE_SIZE;
+	VIOMBDEBUG("%s: swapped in : %lld bytes\n", __func__, s[0].val);
+
+	s[1].tag = VIRTIO_BALLOON_S_SWAP_OUT;
+	s[1].val = uvmexp.pgswapout * PAGE_SIZE;
+	VIOMBDEBUG("%s: swapped out : %lld bytes\n", __func__, s[1].val);
+
+	s[2].tag = VIRTIO_BALLOON_S_MAJFLT;
+	s[2].val = uvmexp.faults;
+	VIOMBDEBUG("%s: faults : %lld\n", __func__, s[2].val);
+
+	s[3].tag = VIRTIO_BALLOON_S_MEMFREE;
+	s[3].val = uvmexp.free * PAGE_SIZE;
+	VIOMBDEBUG("%s: free : %lld bytes\n", __func__, s[3].val);
+
+	s[4].tag = VIRTIO_BALLOON_S_MEMTOT;
+	s[4].val = uvmexp.npages * PAGE_SIZE;
+	VIOMBDEBUG("%s: total : %lld bytes\n", __func__, s[4].val);
+
+	s[5].tag = VIRTIO_BALLOON_S_CACHES;
+	s[5].val = bcstats.numbufpages * PAGE_SIZE;
+	VIOMBDEBUG("%s: cache : %lld  bytes\n", __func__, s[5].val);
+}
diff --git a/sys/arch/amd64/amd64/vmm.c b/sys/arch/amd64/amd64/vmm.c
index 250098471fc..e045ffa4d94 100644
--- a/sys/arch/amd64/amd64/vmm.c
+++ b/sys/arch/amd64/amd64/vmm.c
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmm.c,v 1.254 2019/09/22 08:47:54 mlarkin Exp $	*/
+/*	$OpenBSD: vmm.c,v 1.273 2020/04/19 19:29:52 krw Exp $	*/
 /*
  * Copyright (c) 2014 Mike Larkin <mlarkin@openbsd.org>
  *
@@ -28,7 +28,6 @@
 #include <sys/rwlock.h>
 #include <sys/pledge.h>
 #include <sys/memrange.h>
-#include <sys/timetc.h>
 
 #include <uvm/uvm_extern.h>
 
@@ -66,6 +65,7 @@ void *l1tf_flush_region;
     (VMX_EXIT_INFO_HAVE_RIP | VMX_EXIT_INFO_HAVE_REASON)
 
 struct vm {
 	vm_map_t		 vm_map;
 	uint32_t		 vm_id;
 	pid_t			 vm_creator_pid;
@@ -124,7 +124,9 @@ int vm_get_info(struct vm_info_params *);
 int vm_resetcpu(struct vm_resetcpu_params *);
 int vm_intr_pending(struct vm_intr_params *);
 int vm_rwregs(struct vm_rwregs_params *, int);
 int vm_rwvmparams(struct vm_rwvmparams_params *, int);
+int vm_inflate_balloon(struct vm_inflate_balloon_params *);
 int vm_find(uint32_t, struct vm **);
 int vcpu_readregs_vmx(struct vcpu *, uint64_t, struct vcpu_reg_state *);
 int vcpu_readregs_svm(struct vcpu *, uint64_t, struct vcpu_reg_state *);
@@ -177,7 +179,6 @@ void vmx_handle_intr(struct vcpu *);
 void vmx_handle_intwin(struct vcpu *);
 void vmx_handle_misc_enable_msr(struct vcpu *);
 int vmm_get_guest_memtype(struct vm *, paddr_t);
-int vmm_get_guest_faulttype(void);
 int vmx_get_guest_faulttype(void);
 int svm_get_guest_faulttype(struct vmcb *);
 int vmx_get_exit_qualification(uint64_t *);
@@ -187,6 +188,8 @@ int svm_fault_page(struct vcpu *, paddr_t);
 int vmx_fault_page(struct vcpu *, paddr_t);
 int vmx_handle_np_fault(struct vcpu *);
 int svm_handle_np_fault(struct vcpu *);
+int vmx_mprotect_ept(vm_map_t, paddr_t, paddr_t, int);
+pt_entry_t *vmx_pmap_find_pte_ept(pmap_t, paddr_t);
 int vmm_alloc_vpid(uint16_t *);
 void vmm_free_vpid(uint16_t);
 const char *vcpu_state_decode(u_int);
@@ -202,6 +205,7 @@ void vmx_setmsrbrw(struct vcpu *, uint32_t);
 void svm_set_clean(struct vcpu *, uint32_t);
 void svm_set_dirty(struct vcpu *, uint32_t);
 
+int vmm_gpa_is_valid(struct vcpu *vcpu, paddr_t gpa, size_t obj_size);
 void vmm_init_pvclock(struct vcpu *, paddr_t);
 int vmm_update_pvclock(struct vcpu *);
 
@@ -494,13 +498,18 @@ vmmioctl(dev_t dev, u_long cmd, caddr_t data, int flag, struct proc *p)
 	case VMM_IOC_WRITEREGS:
 		ret = vm_rwregs((struct vm_rwregs_params *)data, 1);
 		break;
+	case VMM_IOC_MPROTECT_EPT:
+		ret = vm_mprotect_ept((struct vm_mprotect_ept_params *)data);
+		break;
 	case VMM_IOC_READVMPARAMS:
 		ret = vm_rwvmparams((struct vm_rwvmparams_params *)data, 0);
 		break;
 	case VMM_IOC_WRITEVMPARAMS:
 		ret = vm_rwvmparams((struct vm_rwvmparams_params *)data, 1);
 		break;
-
+	case VMM_IOC_BALLOON_INFLATE:
+		ret = vm_inflate_balloon((struct vm_inflate_balloon_params *)data);
+		break;
 	default:
 		DPRINTF("%s: unknown ioctl code 0x%lx\n", __func__, cmd);
 		ret = ENOTTY;
@@ -509,6 +518,69 @@ vmmioctl(dev_t dev, u_long cmd, caddr_t data, int flag, struct proc *p)
 	return (ret);
 }
 
+/*
+ * vm_inflate_balloon
+ *
+ * pages should already be unmapped
+ */
+int
+vm_inflate_balloon(struct vm_inflate_balloon_params *vibp)
+{
+	struct vm_page *p;
+	uint64_t hpa;
+	struct vm *vm;
+	struct pmap *pmap;
+	int i, error;
+
+	/* Find the desired VM */
+	rw_enter_read(&vmm_softc->vm_lock);
+	error = vm_find(vibp->vibp_vm_id, &vm);
+	rw_exit_read(&vmm_softc->vm_lock);
+
+	/* Not found? exit. */
+	if (error != 0)
+		return (error);
+
+	pmap = vm->vm_map->pmap;
+
+	for (i = 0; i < vibp->vibp_bl_pages_sz; i++) {
+		printf("%s: got GPPN 0x%llx from vm for inflate "
+		    "%d/%llu\n", __func__, (uint64_t)vibp->vibp_buf_bl_pages[i], i,
+		    (uint64_t)(vibp->vibp_bl_pages_sz));
+
+		if (!pmap_extract(pmap, (vibp->vibp_buf_bl_pages[i] * PAGE_SIZE),
+		    (paddr_t *)&hpa)) {
+			printf("%s: unable to extract HPA for GPA 0x%llx\n",
+			    __func__,
+			    (uint64_t)(vibp->vibp_buf_bl_pages[i] * PAGE_SIZE));
+			 /* XXX
+			 virtual page from VM should be in pmap,
+			 but still are not synced up. It nees a fix
+			 */
+			continue;
+		}
+		printf("%s: GPA: 0x%llx -> HPA 0x%llx\n", __func__,
+		    (uint64_t)(vibp->vibp_buf_bl_pages[i] * PAGE_SIZE),
+		    hpa);
+
+		p = PHYS_TO_VM_PAGE(hpa);
+
+		printf("%s: removing EPT entry for GPA 0x%llx\n",
+		    __func__,
+		    (uint64_t)(vibp->vibp_buf_bl_pages[i] * PAGE_SIZE));
+		pmap_remove(pmap, (vibp->vibp_buf_bl_pages[i] * PAGE_SIZE),
+		    ((vibp->vibp_buf_bl_pages[i] + 1) * PAGE_SIZE));
+
+		printf("%s: freeing vm_page 0x%llx\n", __func__,
+		    (uint64_t)p);
+
+		uvm_pagefree(p);
+	}
+
+	printf("%s: balloon inflate completed\n", __func__);
+	return (0);
+}
+
 /*
  * pledge_ioctl_vmm
  *
@@ -532,8 +604,10 @@ pledge_ioctl_vmm(struct proc *p, long com)
 	case VMM_IOC_INTR:
 	case VMM_IOC_READREGS:
 	case VMM_IOC_WRITEREGS:
 	case VMM_IOC_READVMPARAMS:
 	case VMM_IOC_WRITEVMPARAMS:
+	case VMM_IOC_BALLOON_INFLATE:
 		return (0);
 	}
 
@@ -806,6 +880,288 @@ vm_rwregs(struct vm_rwregs_params *vrwp, int dir)
 	}
 }

diff --git a/sys/arch/amd64/include/vmmvar.h b/sys/arch/amd64/include/vmmvar.h
index 78c477291f2..45383674175 100644
--- a/sys/arch/amd64/include/vmmvar.h
+++ b/sys/arch/amd64/include/vmmvar.h
@@ -1,4 +1,4 @@
-/*	$OpenBSD: vmmvar.h,v 1.67 2019/07/17 05:51:07 pd Exp $	*/
+/*	$OpenBSD: vmmvar.h,v 1.70 2020/04/08 07:39:48 pd Exp $	*/
 /*
  * Copyright (c) 2014 Mike Larkin <mlarkin@openbsd.org>
  *
@@ -18,6 +18,9 @@
 /*
  * CPU capabilities for VMM operation
  */
+
+#include <uvm/uvm_extern.h>
+
 enum {
 	VMM_CPU_MODE_REAL,
 	VMM_CPU_MODE_PROT,
@@ -350,6 +357,12 @@ struct vm_exit_inout {
 	uint16_t		vei_port;	/* port */
 	uint32_t		vei_data;	/* data */
 }; 
struct vm_info_params {
@@ -525,6 +542,14 @@ struct vm_intr_params {
 	uint16_t		vip_intr;
 };
 
+#define BALLOON_MAX_PAGES 256
+struct vm_inflate_balloon_params {
+	/* Input parameters to VMM_IOC_BALLOON_INFLATE */
+	uint32_t		vibp_vm_id;
+	uint32_t		vibp_buf_bl_pages[BALLOON_MAX_PAGES];
+	size_t 			vibp_bl_pages_sz;
+};
+
 #define VM_RWVMPARAMS_PVCLOCK_SYSTEM_GPA 0x1	/* read/write pvclock gpa */
 #define VM_RWVMPARAMS_PVCLOCK_VERSION	 0x2	/* read/write pvclock version */
 #define VM_RWVMPARAMS_ALL	(VM_RWVMPARAMS_PVCLOCK_SYSTEM_GPA | \
@@ -558,6 +583,15 @@ struct vm_rwregs_params {
 	struct vcpu_reg_state	vrwp_regs;
 };
 /* IOCTL definitions */
 #define VMM_IOC_CREATE _IOWR('V', 1, struct vm_create_params) /* Create VM */
 #define VMM_IOC_RUN _IOWR('V', 2, struct vm_run_params) /* Run VCPU */
@@ -571,7 +605,9 @@ struct vm_rwregs_params {
 #define VMM_IOC_READVMPARAMS _IOWR('V', 9, struct vm_rwvmparams_params)
 /* Set VM params */
 #define VMM_IOC_WRITEVMPARAMS _IOW('V', 10, struct vm_rwvmparams_params)
-
+#define VMM_IOC_BALLOON_INFLATE _IOWR('V', 12, struct vm_inflate_balloon_params)

